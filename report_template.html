<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Zipfian Benchmark Report — {{RUN_ID}}</title>
  
  <style>
    :root{
      --bg: #0a0a0a;         /* Deep black background */
      --surface: #1a1a1a;    /* Card background */
      --surface-2: #252525;  /* Elevated surface */
      --text: #ffffff;       /* White text */
      --muted: #a0a0a0;      /* Muted text */
      --muted-2: #808080;    /* More muted */
      --border: rgba(255,255,255,.12);
      
      --brand: #7c3aed;      /* Checkout violet */
      --brand-2: #00d4ff;    /* Checkout cyan */
      --brand-3: #c0ff00;    /* Neon lime (CONNECT button) */
      --accent: #ff2d8d;     /* Magenta accent */
      --ok: #00ff88;         /* Neon green */
      --warn: #ffd000;       /* Bright yellow */
      --bad: #ff4444;        /* Bright red */
      
      --shadow: 0 10px 40px rgba(0,0,0,.6);
      --shadow-soft: 0 6px 20px rgba(0,0,0,.4);
      --glow: 0 0 20px rgba(124,58,237,.4);
      --radius: 18px;
      --radius-sm: 14px;
      
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    }
    
    * { box-sizing: border-box; margin: 0; padding: 0; }
    html, body { height: 100%; }
    body{
      font-family: var(--sans);
      color: var(--text);
      background: var(--bg);
      line-height: 1.6;
    }
    
    /* Container */
    .container{
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 20px;
    }
    
    /* Run badge (used in footer) */
    .run-badge{
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 8px 16px;
      border-radius: 999px;
      background: linear-gradient(90deg, rgba(124,58,237,.25), rgba(0,212,255,.2));
      border: 1px solid rgba(124,58,237,.4);
      font-size: 13px;
      font-weight: 600;
      color: var(--text);
      box-shadow: 0 0 15px rgba(124,58,237,.2);
    }
    .run-badge strong{
      color: var(--brand-2);
      font-weight: 700;
    }
    
    /* Tabs - Checkout.com style */
    .tabs{
      display: flex;
      gap: 32px;
      padding: 16px 0 0;
      border-bottom: 1px solid var(--border);
      overflow-x: auto;
      margin-top: 8px;
    }
    .tab{
      padding: 16px 4px;
      cursor: pointer;
      font-weight: 500;
      font-size: 15px;
      color: var(--muted);
      transition: all 0.3s ease;
      border-bottom: 3px solid transparent;
      white-space: nowrap;
      background: none;
      position: relative;
    }
    .tab:hover{ 
      color: var(--text); 
    }
    .tab.active{
      color: var(--text);
      border-bottom-color: var(--brand-2);
      font-weight: 600;
    }
    
    .tab-content{
      display: none;
      padding: 32px 0 12px;
    }
    .tab-content.active{ display: block; }
    
    /* Hero */
    .hero{
      padding: 60px 0 24px;
    }
    .hero-grid{
      display: grid;
      grid-template-columns: 1fr;
      gap: 32px;
    }
    
    .hero-header{
      text-align: center;
      max-width: 900px;
      margin: 0 auto 48px;
    }
    h1{
      font-size: clamp(32px, 5vw, 44px);
      line-height: 1.15;
      letter-spacing: -0.025em;
      margin-bottom: 16px;
      font-weight: 700;
      color: var(--text);
    }
    .subtitle{
      color: var(--muted);
      font-size: 16px;
      line-height: 1.5;
      max-width: 750px;
      margin: 0 auto 16px;
    }
    .features-badges{
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      justify-content: center;
      margin: 20px auto 20px;
      max-width: 1200px;
    }
    
    .kpi-grid{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      gap: 20px;
      max-width: 900px;
      margin: 0 auto 20px;
    }
    .kpi{
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 24px 20px;
      box-shadow: var(--shadow-soft);
      transition: all 0.3s ease;
      text-align: center;
      position: relative;
      overflow: hidden;
    }
    .kpi::before{
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 3px;
      background: linear-gradient(90deg, var(--brand), var(--brand-2));
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    .kpi:hover{
      transform: translateY(-4px);
      box-shadow: var(--shadow), 0 0 30px rgba(124,58,237,.4);
      border-color: var(--brand);
    }
    .kpi:hover::before{
      opacity: 1;
    }
    .kpi-label{ 
      color: var(--muted); 
      font-size: 12px; 
      text-transform: uppercase;
      font-weight: 600;
      letter-spacing: 0.05em;
      margin-bottom: 12px;
      display: block;
    }
    .kpi-value{ 
      font-weight: 700; 
      font-size: 36px; 
      color: var(--text);
      display: block;
      line-height: 1;
      margin-bottom: 8px;
    }
    .kpi-sub{ 
      color: var(--muted-2); 
      font-size: 13px;
      display: block;
      font-weight: 500;
    }
    
    /* Cards */
    .card{
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 20px;
      box-shadow: var(--shadow-soft);
      margin-bottom: 20px;
    }
    .card h2{
      font-size: 22px;
      letter-spacing: -0.02em;
      margin-bottom: 10px;
      color: var(--text);
    }
    .card h3{
      font-size: 17px;
      margin: 18px 0 10px;
      letter-spacing: -0.01em;
      color: var(--text);
    }
    .card p, .card li{
      color: var(--muted);
      font-size: 15px;
      line-height: 1.6;
    }
    
    /* Grid layouts */
    .grid{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
      gap: 16px;
    }
    
    /* Diagram */
    .diagram{
      width: 100%;
      border-radius: var(--radius);
      border: 1px solid var(--border);
      background: linear-gradient(180deg, rgba(26,26,26,.9), rgba(37,37,37,.85));
      padding: 14px;
      box-shadow: var(--shadow-soft);
    }
    
    /* Table */
    table{
      width: 100%;
      border-collapse: collapse;
      font-size: 14px;
      margin: 16px 0;
    }
    th{
      text-align: left;
      padding: 12px;
      background: var(--surface-2);
      border-bottom: 2px solid var(--border);
      font-weight: 700;
      color: var(--text);
    }
    td{
      padding: 12px;
      border-bottom: 1px solid var(--border);
      color: var(--muted);
    }
    tr:hover td{ background: rgba(124,58,237,.15); }
    
    /* Code blocks */
    pre{
      background: #000000;
      color: #e8edf7;
      padding: 16px;
      border-radius: var(--radius-sm);
      overflow-x: auto;
      font-family: var(--mono);
      font-size: 13px;
      line-height: 1.5;
      box-shadow: inset 0 0 30px rgba(124,58,237,.2), 0 8px 20px rgba(0,0,0,.6);
      margin: 14px 0;
      border: 1px solid rgba(124,58,237,.3);
    }
    code{ font-family: var(--mono); background: rgba(124,58,237,.2); padding: 2px 6px; border-radius: 4px; font-size: 13px; color: var(--brand-3); }
    pre code{ background: none; padding: 0; color: #e8edf7; }
    
    /* Callout */
    .callout{
      background: var(--surface);
      border: 1px solid var(--border);
      padding: 16px 24px;
      border-radius: var(--radius-sm);
      margin: 0 auto;
      max-width: 900px;
      box-shadow: var(--shadow-soft);
      text-align: center;
      font-size: 15px;
      transition: all 0.3s ease;
    }
    .callout:hover{
      transform: translateY(-2px);
      box-shadow: 0 8px 24px rgba(0,0,0,.4), 0 0 30px rgba(124,58,237,.4);
      border-color: var(--brand);
      background: rgba(124,58,237,.08);
    }
    .callout strong{ 
      color: var(--brand-2); 
      text-shadow: 0 0 10px rgba(0,212,255,.3);
      font-weight: 700;
    }
    
    /* Chart card styling */
    .chart-card{
      padding: 0;
      overflow: hidden;
    }
    .chart-header{
      padding: 12px 12px 8px;
      border-bottom: 1px solid var(--border);
    }
    .chart-header h3{
      margin: 0 0 6px;
      font-size: 18px;
      color: var(--text);
    }
    .chart-header p{
      margin: 0;
      font-size: 13px;
      color: var(--muted);
    }
    
    /* Chart embed - Light background for charts */
    .chart-embed{
      width: 100%;
      border-radius: 0;
      border: none;
      box-shadow: none;
      margin: 0;
      background: #f8f9fa;
      padding: 24px;
      display: block;
      cursor: zoom-in;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    .chart-embed:hover{
      transform: scale(1.01);
      box-shadow: 0 8px 32px rgba(124,58,237,.3);
    }
    
    /* Modal for enlarged charts */
    .chart-modal{
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0,0,0,.95);
      z-index: 10000;
      align-items: center;
      justify-content: center;
      padding: 40px;
      animation: fadeIn 0.2s ease;
    }
    .chart-modal.active{
      display: flex;
    }
    .chart-modal-content{
      max-width: 95%;
      max-height: 95%;
      object-fit: contain;
      border-radius: var(--radius);
      box-shadow: 0 20px 80px rgba(0,0,0,.8);
      animation: zoomIn 0.3s ease;
    }
    .chart-modal-close{
      position: absolute;
      top: 20px;
      right: 20px;
      width: 48px;
      height: 48px;
      border: none;
      background: rgba(255,255,255,.1);
      backdrop-filter: blur(10px);
      color: white;
      font-size: 28px;
      font-weight: 300;
      cursor: pointer;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.2s ease;
      z-index: 10001;
    }
    .chart-modal-close:hover{
      background: rgba(255,68,68,.8);
      transform: scale(1.1);
    }
    
    @keyframes fadeIn{
      from{ opacity: 0; }
      to{ opacity: 1; }
    }
    @keyframes zoomIn{
      from{ transform: scale(0.9); opacity: 0; }
      to{ transform: scale(1); opacity: 1; }
    }
    
    /* Tags */
    .tag{
      display: inline-flex;
      align-items: center;
      padding: 8px 14px;
      border-radius: 999px;
      font-size: 13px;
      font-weight: 600;
      transition: all 0.2s ease;
      white-space: nowrap;
    }
    .tag:hover{
      transform: translateY(-1px);
    }
    .tag.ok{ 
      background: rgba(0,255,136,.2); 
      color: var(--ok); 
      border: 1px solid rgba(0,255,136,.4); 
      box-shadow: 0 0 15px rgba(0,255,136,.2);
    }
    .tag.warn{ 
      background: rgba(255,208,0,.2); 
      color: var(--warn); 
      border: 1px solid rgba(255,208,0,.4); 
      box-shadow: 0 0 15px rgba(255,208,0,.2);
    }
    .tag.bad{ 
      background: rgba(255,68,68,.2); 
      color: var(--bad); 
      border: 1px solid rgba(255,68,68,.4); 
      box-shadow: 0 0 15px rgba(255,68,68,.2);
    }
    .tag.info{ 
      background: rgba(0,212,255,.2); 
      color: var(--brand-2); 
      border: 1px solid rgba(0,212,255,.4); 
      box-shadow: 0 0 15px rgba(0,212,255,.2);
    }
    
    /* Details/Summary */
    details{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 12px;
      margin: 12px 0;
    }
    summary{
      cursor: pointer;
      font-weight: 650;
      color: var(--text);
      list-style: none;
    }
    summary::-webkit-details-marker{ display: none; }
    summary::before{
      content: "▶";
      display: inline-block;
      margin-right: 8px;
      transition: transform 0.2s;
      color: var(--brand-3);
      text-shadow: 0 0 10px rgba(192,255,0,.5);
    }
    details[open] summary::before{ transform: rotate(90deg); }
    
    /* Footer */
    footer{
      padding: 32px 0;
      color: var(--muted-2);
      font-size: 13px;
      border-top: 2px solid var(--border);
      margin-top: 20px;
      background: rgba(10,10,10,.8);
    }
    footer strong{ color: var(--text); }
    footer code{
      background: rgba(124,58,237,.15);
      color: var(--muted);
      padding: 2px 8px;
      border-radius: 4px;
      font-size: 11px;
    }
    
    ul.list{
      padding-left: 20px;
      margin: 12px 0;
    }
    ul.list li{
      margin: 8px 0;
    }
    
    /* Executive Summary Styles */
    .eyebrow{
      font-size: 12px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.1em;
      color: var(--brand-2);
      margin-bottom: 12px;
    }
    .section-title{
      font-size: 32px;
      font-weight: 700;
      margin-bottom: 16px;
      color: var(--text);
    }
    .section-subtitle{
      font-size: 16px;
      line-height: 1.6;
      color: var(--muted);
      margin-bottom: 32px;
      max-width: 1100px;
    }
    
    .callout-grid{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
      gap: 20px;
      margin: 32px 0;
    }
    .callout-card{
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 24px;
      transition: all 0.3s ease;
    }
    .callout-card:hover{
      transform: translateY(-4px);
      box-shadow: var(--shadow), 0 0 30px rgba(124,58,237,.3);
      border-color: var(--brand);
    }
    .callout-label{
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      color: var(--muted);
      margin-bottom: 12px;
    }
    .callout-value{
      font-size: 20px;
      font-weight: 700;
      color: var(--text);
      margin-bottom: 12px;
      line-height: 1.2;
    }
    .callout-footnote{
      font-size: 13px;
      color: var(--muted-2);
      line-height: 1.5;
    }
    
    .content-grid{
      display: grid;
      gap: 24px;
      margin: 32px 0;
    }
    .content-grid.two-col{
      grid-template-columns: 1fr 1fr;
    }
    .content-grid.three-col{
      grid-template-columns: repeat(3, 1fr);
    }
    @media (max-width: 900px){
      .content-grid.two-col{ grid-template-columns: 1fr; }
      .content-grid.three-col{ grid-template-columns: 1fr; }
    }
    
    .content-card{
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 24px;
      box-shadow: var(--shadow-soft);
      transition: all 0.3s ease;
    }
    .content-card:hover{
      transform: translateY(-2px);
      box-shadow: 0 8px 24px rgba(0,0,0,.4), 0 0 30px rgba(124,58,237,.3);
      border-color: var(--brand);
    }
    .card-title{
      font-size: 18px;
      font-weight: 700;
      margin-bottom: 16px;
      color: var(--text);
    }
    .card-body{
      font-size: 15px;
      color: var(--muted);
      line-height: 1.6;
      margin-bottom: 20px;
    }
    
    .bullets{
      list-style: none;
      padding: 0;
      margin: 0;
    }
    .bullets li{
      padding-left: 24px;
      margin: 12px 0;
      position: relative;
      color: var(--muted);
      font-size: 15px;
      line-height: 1.6;
    }
    .bullets li::before{
      content: "→";
      position: absolute;
      left: 0;
      color: var(--brand-2);
      font-weight: 700;
    }
    
    .quote-block{
      background: rgba(124,58,237,.1);
      border-left: 4px solid var(--brand);
      padding: 20px;
      border-radius: var(--radius-sm);
      margin-top: 24px;
    }
    .quote{
      font-size: 16px;
      font-weight: 600;
      color: var(--text);
      margin-bottom: 8px;
      font-style: italic;
    }
    .quote-sub{
      font-size: 14px;
      color: var(--muted);
      margin: 0;
    }
    
    .mini-metrics{
      display: flex;
      flex-direction: column;
      gap: 16px;
      margin: 20px 0;
    }
    .mini-metric{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 16px;
    }
    .metric-name{
      font-size: 14px;
      font-weight: 700;
      color: var(--brand-2);
      margin-bottom: 8px;
    }
    .metric-desc{
      font-size: 13px;
      color: var(--muted);
      line-height: 1.5;
    }
    
    .chart-frame{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 12px;
      margin-top: 24px;
      transition: all 0.3s ease;
      display: flex;
      flex-direction: column;
    }
    .chart-frame:hover{
      transform: translateY(-2px);
      box-shadow: 0 8px 24px rgba(0,0,0,.4), 0 0 30px rgba(124,58,237,.2);
      border-color: var(--brand);
    }
    .chart-title{
      font-size: 14px;
      font-weight: 700;
      color: var(--text);
      margin-bottom: 6px;
      /* Clamp long titles to 2 lines for consistent layout */
      display: -webkit-box;
      -webkit-line-clamp: 2;
      -webkit-box-orient: vertical;
      overflow: hidden;
    }
    .chart-note{
      font-size: 13px;
      color: var(--muted);
      line-height: 1.5;
      margin-bottom: 16px;
      /* Clamp long notes to 2 lines for consistent layout */
      display: -webkit-box;
      -webkit-line-clamp: 2;
      -webkit-box-orient: vertical;
      overflow: hidden;
    }
    /* Guarantee consistent chart image area regardless of title/note wrapping */
    .chart-content{
      flex: 1;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .chart-embed{
      width: 100%;
      height: auto;
      border-radius: 8px;
    }
    
    /* Chart panel wrapper - ensure no interference with flex layout */
    .chart-panel{
      width: 100%;
      height: 100%;
    }
    
    /* Chart button navigation */
    .chart-btn:hover{
      transform: translateX(4px);
      box-shadow: 0 4px 12px rgba(0,0,0,.3);
    }
    .chart-placeholder{
      background: #f8f9fa;
      border: 2px dashed var(--border);
      border-radius: var(--radius-sm);
      padding: 60px 20px;
      text-align: center;
      min-height: 300px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .placeholder-inner{
      max-width: 400px;
    }
    .placeholder-badge{
      display: inline-block;
      padding: 6px 12px;
      background: rgba(124,58,237,.2);
      color: var(--brand);
      border-radius: 999px;
      font-size: 12px;
      font-weight: 600;
      margin-bottom: 12px;
    }
    .placeholder-inner p{
      font-size: 14px;
      color: var(--muted);
      margin: 0;
    }
    .chart-caption{
      font-size: 13px;
      color: var(--muted);
      margin-top: 8px;
      line-height: 1.5;
    }
    
    .takeaway-banner{
      background: linear-gradient(135deg, rgba(124,58,237,.2), rgba(0,212,255,.15));
      border: 1px solid rgba(124,58,237,.4);
      border-radius: var(--radius);
      padding: 28px;
      margin: 32px 0;
      box-shadow: 0 0 30px rgba(124,58,237,.2);
    }
    .takeaway-title{
      font-size: 12px;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 0.1em;
      color: var(--brand-2);
      margin-bottom: 12px;
    }
    .takeaway-body{
      font-size: 17px;
      line-height: 1.6;
      color: var(--text);
    }
    
    /* Workload Reality Tab Styles */
    .diagram-frame{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 20px;
      margin-top: 24px;
    }
    .diagram-title{
      font-size: 14px;
      font-weight: 700;
      color: var(--text);
      margin-bottom: 16px;
    }
    .diagram-placeholder{
      background: linear-gradient(180deg, rgba(26,26,26,.9), rgba(37,37,37,.85));
      border: 2px dashed var(--border);
      border-radius: var(--radius-sm);
      padding: 60px 20px;
      text-align: center;
      min-height: 280px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    .insight-box{
      background: rgba(0,255,136,.1);
      border: 1px solid rgba(0,255,136,.3);
      border-radius: var(--radius-sm);
      padding: 14px 16px;
      margin-top: 24px;
    }
    .insight-title{
      font-size: 14px;
      font-weight: 700;
      color: var(--ok);
      margin-bottom: 10px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }
    .insight-body{
      font-size: 15px;
      color: var(--muted);
      line-height: 1.6;
    }
    
    .math-callout{
      background: rgba(255,208,0,.1);
      border: 1px solid rgba(255,208,0,.3);
      border-left: 4px solid var(--warn);
      border-radius: var(--radius-sm);
      padding: 14px 16px;
      margin: 20px 0;
    }
    .math-title{
      font-size: 14px;
      font-weight: 700;
      color: var(--warn);
      margin-bottom: 12px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }
    .math-body{
      font-size: 14px;
      color: var(--muted);
      line-height: 1.6;
    }
    .math-body p{
      margin: 8px 0;
    }
    .code-block{
      background: #000000;
      color: var(--brand-3);
      padding: 12px 16px;
      border-radius: 6px;
      font-family: var(--mono);
      font-size: 14px;
      margin: 12px 0;
      border: 1px solid rgba(192,255,0,.3);
      box-shadow: inset 0 0 20px rgba(192,255,0,.1);
    }
    
    /* Benchmark Design Tab Styles */
    .code-callout{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 16px;
      margin: 20px 0;
    }
    .code-title{
      font-size: 13px;
      font-weight: 700;
      color: var(--brand-2);
      margin-bottom: 12px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }
    .code-callout .code-block{
      margin: 0;
      background: #000000;
      color: #e8edf7;
      padding: 16px;
      border-radius: 8px;
      overflow-x: auto;
      font-family: var(--mono);
      font-size: 13px;
      line-height: 1.6;
      border: 1px solid rgba(124,58,237,.3);
      box-shadow: inset 0 0 30px rgba(124,58,237,.15);
    }
    .code-callout .code-block code{
      color: #e8edf7;
      background: none;
      padding: 0;
    }
    
    /* Results Tab Styles */
    .chart-placeholder{
      background: #f8f9fa;
      border: 2px dashed var(--border);
      border-radius: var(--radius-sm);
      padding: 40px 20px;
      text-align: center;
      color: var(--muted);
      min-height: 300px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .placeholder-inner{
      max-width: 400px;
    }
    .placeholder-badge{
      display: inline-block;
      background: var(--brand-1);
      color: white;
      padding: 6px 16px;
      border-radius: 20px;
      font-size: 12px;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 16px;
    }
    .placeholder-inner p{
      font-size: 14px;
      line-height: 1.6;
      color: var(--muted);
      margin: 0;
    }
    .bullets.small{
      font-size: 13px;
      line-height: 1.8;
    }
    .bullets.small li{
      margin-bottom: 6px;
    }
    .callout-card.emphasis{
      background: linear-gradient(135deg, rgba(124,58,237,.15) 0%, rgba(0,212,255,.1) 100%);
      border: 1px solid var(--brand-1);
      box-shadow: 0 0 30px rgba(124,58,237,.2);
    }
    .callout-card.emphasis .callout-label{
      color: var(--brand-2);
    }
    .callout-card.emphasis .callout-value{
      color: var(--brand-3);
    }
    
    /* Pattern List Styles */
    .pattern-list{
      display: flex;
      flex-direction: column;
      gap: 16px;
      margin: 20px 0;
    }
    .pattern-item{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-left: 4px solid var(--brand-2);
      border-radius: var(--radius-sm);
      padding: 16px 20px;
      transition: all 0.2s ease;
    }
    .pattern-item:hover{
      border-left-color: var(--brand-3);
      transform: translateX(4px);
      box-shadow: 0 4px 12px rgba(0,0,0,.2);
    }
    .pattern-title{
      font-size: 15px;
      font-weight: 700;
      color: var(--brand-2);
      margin-bottom: 8px;
      letter-spacing: -0.01em;
    }
    .pattern-body{
      font-size: 14px;
      line-height: 1.7;
      color: var(--muted);
      margin: 0;
    }
    
    /* Math Callout Styles */
    .math-callout{
      background: linear-gradient(135deg, rgba(124,58,237,.1) 0%, rgba(0,212,255,.05) 100%);
      border: 1px solid rgba(124,58,237,.4);
      border-radius: var(--radius-sm);
      padding: 14px 16px;
      margin: 20px 0;
      box-shadow: 0 0 20px rgba(124,58,237,.15);
    }
    .math-row{
      display: flex;
      align-items: center;
      gap: 16px;
      padding: 12px 0;
      font-family: var(--mono);
    }
    .math-row:not(:last-child){
      border-bottom: 1px solid rgba(124,58,237,.2);
    }
    .math-label{
      font-size: 14px;
      font-weight: 700;
      color: var(--brand-2);
      min-width: 80px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }
    .math-expr{
      font-size: 15px;
      color: var(--brand-3);
      font-weight: 600;
      letter-spacing: -0.01em;
    }
    .math-note{
      margin-top: 16px;
      padding: 12px 16px;
      background: rgba(0,0,0,.3);
      border-left: 3px solid var(--brand-3);
      border-radius: 4px;
      font-size: 13px;
      line-height: 1.7;
      color: var(--muted);
      font-family: var(--sans);
    }
    .math-note b{
      color: var(--brand-2);
      font-weight: 700;
    }
    
    /* Compact Callout Box Styles (for Tab 2 LHS) */
    .callout-box {
      background: linear-gradient(135deg, rgba(124,58,237,.1) 0%, rgba(0,212,255,.05) 100%);
      border: 1px solid rgba(124,58,237,.4);
      border-radius: var(--radius-sm);
      padding: 16px 18px;
      margin: 12px 0;
      box-shadow: 0 0 20px rgba(124,58,237,.15);
    }
    .callout-box--purple {
      background: linear-gradient(135deg, rgba(124,58,237,.12) 0%, rgba(0,212,255,.06) 100%);
      border: 1px solid rgba(124,58,237,.5);
    }
    .callout-box__title {
      font-size: 13px;
      font-weight: 700;
      color: var(--brand);
      margin-bottom: 12px;
      text-transform: uppercase;
      letter-spacing: 0.08em;
    }
    .callout-lead {
      font-size: 14px;
      color: var(--muted);
      line-height: 1.6;
      margin-bottom: 12px;
    }
    .callout-box--purple .callout-lead {
      margin-bottom: 8px;
      opacity: 0.9;
    }
    .math-panel {
      background: rgba(0,0,0,.35);
      border-radius: 8px;
      padding: 12px 14px;
      margin: 8px 0 0 0;
    }
    .math-panel pre {
      margin: 0;
      font-family: var(--mono);
      font-size: 13px;
      line-height: 1.6;
      color: var(--brand-3);
    }
    .math-panel code {
      font-family: var(--mono);
      color: var(--brand-3);
    }
    .callout-interpretation {
      margin-top: 10px;
      font-size: 13px;
      opacity: 0.75;
      color: var(--muted);
      line-height: 1.7;
      padding-left: 2px;
    }
    .callout-interpretation b {
      color: var(--brand-2);
      font-weight: 700;
    }
    
    /* Story Steps Styles */
    .story-steps{
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin: 24px 0;
    }
    .story-step{
      display: flex;
      align-items: flex-start;
      gap: 20px;
      padding: 20px;
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      transition: all 0.2s ease;
    }
    .story-step:hover{
      border-color: var(--brand-2);
      box-shadow: 0 4px 16px rgba(0,212,255,.15);
      transform: translateX(4px);
    }
    .step-number{
      flex-shrink: 0;
      width: 40px;
      height: 40px;
      display: flex;
      align-items: center;
      justify-content: center;
      background: linear-gradient(135deg, var(--brand-1) 0%, var(--brand-2) 100%);
      color: white;
      font-size: 18px;
      font-weight: 700;
      border-radius: 50%;
      box-shadow: 0 0 20px rgba(124,58,237,.4);
    }
    .step-body{
      flex: 1;
      font-size: 15px;
      line-height: 1.7;
      color: var(--text);
      padding-top: 8px;
    }
    .step-body b{
      color: var(--brand-2);
      font-weight: 700;
    }
    
    /* Recommendations Tab Styles */
    .recommendation-stack{
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin: 24px 0;
    }
    .rec-item{
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-left: 4px solid var(--brand-3);
      border-radius: var(--radius-sm);
      padding: 20px 24px;
      transition: all 0.2s ease;
    }
    .rec-item:hover{
      border-left-color: var(--brand-2);
      box-shadow: 0 4px 16px rgba(192,255,0,.15);
      transform: translateX(4px);
    }
    .rec-title{
      font-size: 16px;
      font-weight: 700;
      color: var(--brand-3);
      margin-bottom: 10px;
      letter-spacing: -0.01em;
    }
    .rec-body{
      font-size: 14px;
      line-height: 1.7;
      color: var(--muted);
      margin: 0;
    }
    .rec-body b{
      color: var(--brand-2);
      font-weight: 700;
    }
    
    /* Operations Grid Styles */
    .ops-grid{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 20px;
      margin: 24px 0;
    }
    .ops-item{
      background: linear-gradient(135deg, var(--surface-2) 0%, var(--surface) 100%);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      padding: 24px;
      transition: all 0.2s ease;
    }
    .ops-item:hover{
      border-color: var(--brand-2);
      box-shadow: 0 8px 24px rgba(0,0,0,.3);
      transform: translateY(-4px);
    }
    .ops-title{
      font-size: 15px;
      font-weight: 700;
      color: var(--brand-2);
      margin-bottom: 12px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }
    .ops-body{
      font-size: 14px;
      line-height: 1.7;
      color: var(--muted);
      margin: 0;
    }
    .ops-body b{
      color: var(--text);
      font-weight: 600;
    }
    
    /* Appendix tab styles */
    .code-frame{
      margin: 24px 0;
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      background: var(--surface);
      overflow: hidden;
    }
    .code-title{
      padding: 12px 20px;
      background: var(--surface-2);
      font-weight: 600;
      font-size: 14px;
      color: var(--muted);
      border-bottom: 1px solid var(--border);
    }
    .code-block{
      margin: 0;
      padding: 20px;
      font-family: var(--mono);
      font-size: 13px;
      line-height: 1.6;
      color: var(--text);
      background: var(--surface);
      overflow-x: auto;
    }
    .code-caption{
      padding: 12px 20px;
      font-size: 13px;
      color: var(--muted);
      background: var(--surface-2);
      border-top: 1px solid var(--border);
    }
    
    .metric-grid{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 16px;
      margin: 24px 0;
    }
    .metric-box{
      padding: 20px;
      background: var(--surface-2);
      border-radius: var(--radius-sm);
      border: 1px solid var(--border);
      text-align: center;
    }
    .metric-label{
      font-size: 12px;
      font-weight: 600;
      color: var(--muted);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 8px;
    }
    .metric-value{
      font-size: 28px;
      font-weight: 700;
      color: var(--text);
      margin-bottom: 4px;
    }
    .metric-note{
      font-size: 13px;
      color: var(--muted-2);
    }
    
    .checklist-grid{
      display: grid;
      gap: 16px;
      margin: 24px 0;
    }
    .checklist-item{
      display: flex;
      gap: 16px;
      padding: 20px;
      background: var(--surface);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
      align-items: flex-start;
    }
    .checklist-icon{
      width: 32px;
      height: 32px;
      border-radius: 50%;
      background: var(--ok);
      color: var(--bg);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 18px;
      flex-shrink: 0;
    }
    .checklist-content{
      flex: 1;
    }
    .checklist-title{
      font-weight: 600;
      font-size: 15px;
      color: var(--text);
      margin-bottom: 6px;
    }
    .checklist-text{
      font-size: 14px;
      color: var(--muted);
      line-height: 1.5;
    }
    
    .reference-links{
      display: grid;
      gap: 16px;
      margin: 24px 0;
    }
    .reference-item{
      padding: 20px;
      background: var(--surface-2);
      border: 1px solid var(--border);
      border-radius: var(--radius-sm);
    }
    .reference-title{
      font-weight: 600;
      font-size: 15px;
      color: var(--text);
      margin-bottom: 8px;
    }
    .reference-path{
      font-family: var(--mono);
      font-size: 13px;
      color: var(--brand-2);
      margin-bottom: 6px;
    }
    .reference-desc{
      font-size: 13px;
      color: var(--muted);
    }
    
    /* ========================================
       TEMPLATE A: KPI ROW
       ======================================== */
    .kpi-row{
      display:grid;
      grid-template-columns: repeat(4, minmax(0,1fr));
      gap:16px;
      margin: 14px 0 18px;
    }
    .kpi-card{
      background: rgba(255,255,255,.04);
      border: 1px solid rgba(255,255,255,.08);
      border-radius: 18px;
      padding: 16px 16px 14px;
      box-shadow: 0 10px 30px rgba(0,0,0,.28);
    }
    .kpi-card.kpi-accent{
      border-color: rgba(0,255,178,.25);
      box-shadow: 0 12px 36px rgba(0,255,178,.08);
    }
    .kpi-label{
      font-size: 12px;
      letter-spacing: .12em;
      text-transform: uppercase;
      color: rgba(255,255,255,.62);
      margin-bottom: 10px;
    }
    .kpi-value{
      font-size: 36px;
      font-weight: 650;
      line-height: 1.1;
      color: rgba(255,255,255,.95);
    }
    .kpi-unit{
      font-size: 16px;
      margin-left: 6px;
      color: rgba(255,255,255,.65);
      font-weight: 600;
    }
    .kpi-sub{
      margin-top: 10px;
      font-size: 13px;
      color: rgba(255,255,255,.70);
    }
    @media (max-width: 980px){
      .kpi-row{ grid-template-columns: repeat(2, minmax(0,1fr)); }
    }
    
    /* ========================================
       TEMPLATE B: TABBED CHART CARD
       ======================================== */
    .chart-card{
      background: rgba(255,255,255,.03);
      border: 1px solid rgba(255,255,255,.08);
      border-radius: 22px;
      padding: 18px;
      box-shadow: 0 12px 34px rgba(0,0,0,.32);
      margin-bottom: 20px;
    }
    .chart-card-head{
      display:flex;
      align-items:flex-start;
      justify-content:space-between;
      gap:14px;
      margin-bottom: 12px;
    }
    .chart-card-title{ 
      font-size: 18px; 
      font-weight: 650; 
      color: rgba(255,255,255,.95); 
    }
    .chart-card-sub{ 
      margin-top:6px; 
      font-size: 13px; 
      color: rgba(255,255,255,.68); 
      max-width: 70ch; 
    }
    
    .seg-tabs{
      display:inline-flex;
      background: rgba(255,255,255,.04);
      border: 1px solid rgba(255,255,255,.08);
      border-radius: 14px;
      padding: 4px;
      gap: 4px;
      flex-wrap: wrap;
    }
    .seg-tab{
      appearance:none;
      border: 0;
      background: transparent;
      color: rgba(255,255,255,.72);
      padding: 8px 10px;
      font-size: 12px;
      border-radius: 11px;
      cursor: pointer;
      font-weight: 600;
    }
    .seg-tab.is-active{
      background: rgba(255,255,255,.10);
      color: rgba(255,255,255,.92);
      box-shadow: 0 6px 16px rgba(0,0,0,.22);
    }
    
    .tab-panels{ margin-top: 10px; }
    .tab-panel{ display:none; }
    .tab-panel.is-active{ display:block; }
    
    .chart-frame{
      background: #fff;
      border-radius: 16px;
      padding: 12px;
      overflow:hidden;
    }
    .chart-frame img{
      width:100%;
      height:auto;
      display:block;
      border-radius: 12px;
    }
    .chart-note{
      margin-top: 10px;
      font-size: 13px;
      color: rgba(255,255,255,.72);
    }
    
    @media (max-width: 980px){
      .chart-card-head{ flex-direction: column; }
      .chart-card-sub{ max-width: none; }
    }
    
    /* ========================================
       TEMPLATE C: COMPARISON GRID
       ======================================== */
    .cmp-grid{
      display:grid;
      grid-template-columns: repeat(2, minmax(0,1fr));
      gap: 16px;
      margin-bottom: 20px;
    }
    .cmp-card{
      background: rgba(255,255,255,.03);
      border: 1px solid rgba(255,255,255,.08);
      border-radius: 22px;
      padding: 16px;
      box-shadow: 0 12px 34px rgba(0,0,0,.32);
    }
    .cmp-card.cmp-accent{
      border-color: rgba(125,79,255,.28);
      box-shadow: 0 12px 38px rgba(125,79,255,.10);
    }
    .cmp-title{
      font-size: 15px;
      font-weight: 650;
      color: rgba(255,255,255,.95);
    }
    .cmp-sub{
      margin-top: 6px;
      font-size: 13px;
      color: rgba(255,255,255,.66);
      margin-bottom: 10px;
    }
    .cmp-bullets{
      margin: 10px 0 0;
      padding: 0;
      list-style: none;
      display: grid;
      gap: 8px;
    }
    .cmp-bullets li{
      display:flex;
      align-items:center;
      gap:10px;
      font-size: 13px;
      color: rgba(255,255,255,.72);
    }
    .dot{
      width: 8px;
      height: 8px;
      border-radius: 50%;
      display:inline-block;
      background: rgba(255,255,255,.28);
    }
    .dot-ok{ background: rgba(0,255,178,.70); }
    .dot-warn{ background: rgba(255,193,77,.78); }
    
    @media (max-width: 980px){
      .cmp-grid{ grid-template-columns: 1fr; }
    }
  </style>
</head>
<body>

  <!-- Main Content -->
  <div class="container">
    
    <!-- Hero -->
    <section class="hero">
      <div class="hero-header">
        <h1>Lakebase Feature Serving Benchmark</h1>
        <p class="subtitle">
          Production-grade performance analysis for payment transaction workloads.
          Measures serial, bin-packed, and parallel execution modes under realistic <strong>cold-read scenarios</strong> (0-20% cache hits).
        </p>
      </div>
      
      <div class="kpi-grid">
        <div class="kpi">
          <span class="kpi-label">Best P99 Achieved</span>
          <span class="kpi-value" id="bestP99" style="color: var(--ok);">45ms</span>
          <span class="kpi-sub">Parallel (8 workers)</span>
        </div>
        <div class="kpi">
          <span class="kpi-label">vs Target</span>
          <span class="kpi-value" id="improvement" style="color: var(--brand-2);">43%</span>
          <span class="kpi-sub">faster than 79ms SLA</span>
        </div>
        <div class="kpi">
          <span class="kpi-label">Total Queries</span>
          <span class="kpi-value" id="totalQueries">300K+</span>
          <span class="kpi-sub">across all modes</span>
        </div>
        <div class="kpi">
          <span class="kpi-label">Dataset Size</span>
          <span class="kpi-value" id="datasetSize">15K</span>
          <span class="kpi-sub">unique keys, 3 entities</span>
        </div>
      </div>
      
      <div class="features-badges">
        <div class="tag ok">✓ No EXPLAIN contamination</div>
        <div class="tag ok">✓ Top-up key sampling</div>
        <div class="tag ok">✓ Pool wait tracked</div>
        <div class="tag ok">✓ Schema migrations</div>
        <div class="tag ok">✓ Slow query logging</div>
      </div>
      
      <div class="callout" style="margin-bottom: 0;">
        <strong>Production Baseline:</strong> Checkout.com P99 target = <span style="color: var(--brand-2); font-weight: 800;">79ms</span> 
        (verified from production traffic, primarily cold reads)
      </div>
    </section>

    <!-- Tabs -->
    <div class="tabs">
      <div class="tab active" onclick="switchTab('executive-summary', this)">Executive Summary</div>
      <div class="tab" onclick="switchTab('workload-reality', this)">Workload Reality</div>
      <div class="tab" onclick="switchTab('benchmark-design', this)">Benchmark Design</div>
      <div class="tab" onclick="switchTab('results-latency-hot', this)">Results - Latency</div>
      <div class="tab" onclick="switchTab('what-dominates-p99', this)">What Dominates P99</div>
      <div class="tab" onclick="switchTab('binpacking-efficiency', this)">Bin-packing</div>
      <div class="tab" onclick="switchTab('parallelism-diminishing-returns', this)">Parallelism</div>
      <div class="tab" onclick="switchTab('overlap-gantt', this)">Gantt View</div>
      <div class="tab" onclick="switchTab('recommendations-next-steps', this)">Recommendations</div>
      <div class="tab" onclick="switchTab('appendix', this)">Appendix</div>
    </div>

    <!-- Tab: Executive Summary -->
    <!-- Tab: Executive Summary -->
    <div id="tab-executive-summary" class="tab-content active">
      <div class="section">
        <div class="section-title">Executive Summary</div>
        <div class="section-subtitle">
          Can Lakebase serve a <strong>DynamoDB-style feature store</strong> workload with predictable tail latency when a single request fans out across dozens of tables?
        </div>

        <div class="content-grid" style="margin-bottom: 0;">
          <!-- Left: story + schematic -->
          <div class="content-card">
            <h3>What we're benchmarking</h3>
            <p>
              A realistic online-feature lookup pattern: <strong>one request = 3 entities</strong>
              (card fingerprint, customer email, cardholder name) and each entity fans out to
              <strong>9–12 point lookups</strong> across a feature-table family (≈30 total lookups per request).
            </p>

            <div class="callout" style="max-width: 100%;">
              <strong>This workload punishes fan-out, not throughput.</strong><br/>
              Even if individual lookups are fast, the request tail is dominated by the chance that
              <em>at least one</em> lookup is slow—especially under predominantly cold reads.
            </div>

            <!-- Asymmetric layout: Large fan-out schematic + smaller tail amplification -->
            <div style="display: grid; grid-template-columns: 2fr 1fr; gap: 16px; margin-top: 12px;">
              <div class="content-card" style="padding: 20px;">
                <h4 style="margin: 0 0 14px 0;">Fan-out schematic</h4>
                <svg viewBox="0 0 860 220" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="Fan-out schematic"
                     style="width:100%;height:auto;border-radius:14px;border:1px solid rgba(0,0,0,0.06);background:#fff;">
                  <defs>
                    <marker id="arrow_exec" viewBox="0 0 10 10" refX="9" refY="5" markerWidth="7" markerHeight="7" orient="auto-start-reverse">
                      <path d="M 0 0 L 10 5 L 0 10 z" fill="#111827"/>
                    </marker>
                  </defs>

                  <style>
                    .b { fill:#ffffff; stroke:rgba(0,0,0,0.12); stroke-width:1.2; }
                    .t1 { font: 600 18px system-ui, -apple-system, Segoe UI, Roboto, Arial; fill:#111827; }
                    .t2 { font: 500 14px system-ui, -apple-system, Segoe UI, Roboto, Arial; fill:#374151; }
                    .ln { stroke:#111827; stroke-width:1.6; fill:none; marker-end:url(#arrow_exec); }
                  </style>

                  <!-- Request -->
                  <rect class="b" x="20" y="80" width="150" height="60" rx="14"/>
                  <text class="t1" x="95" y="114" text-anchor="middle">1 request</text>

                  <!-- Entities -->
                  <rect class="b" x="250" y="25" width="190" height="50" rx="14"/>
                  <text class="t1" x="345" y="57" text-anchor="middle">Entity A</text>

                  <rect class="b" x="250" y="85" width="190" height="50" rx="14"/>
                  <text class="t1" x="345" y="117" text-anchor="middle">Entity B</text>

                  <rect class="b" x="250" y="145" width="190" height="50" rx="14"/>
                  <text class="t1" x="345" y="177" text-anchor="middle">Entity C</text>

                  <!-- Table fanout blocks -->
                  <rect class="b" x="520" y="18" width="320" height="62" rx="14"/>
                  <text class="t1" x="680" y="48" text-anchor="middle">9–12 table lookups</text>
                  <text class="t2" x="680" y="68" text-anchor="middle">per entity (SELECT * · LIMIT 1)</text>

                  <rect class="b" x="520" y="80" width="320" height="62" rx="14"/>
                  <text class="t1" x="680" y="110" text-anchor="middle">9–12 table lookups</text>
                  <text class="t2" x="680" y="130" text-anchor="middle">per entity</text>

                  <rect class="b" x="520" y="142" width="320" height="62" rx="14"/>
                  <text class="t1" x="680" y="172" text-anchor="middle">9–12 table lookups</text>
                  <text class="t2" x="680" y="192" text-anchor="middle">per entity</text>

                  <!-- Arrows -->
                  <path class="ln" d="M170 110 L250 50"/>
                  <path class="ln" d="M170 110 L250 110"/>
                  <path class="ln" d="M170 110 L250 170"/>

                  <path class="ln" d="M440 50 L520 50"/>
                  <path class="ln" d="M440 110 L520 110"/>
                  <path class="ln" d="M440 170 L520 170"/>
                </svg>

                <div class="callout-footnote" style="margin-top:14px;">
                  Request latency is the critical path:
                  <strong>Serial</strong> ≈ Σ(entity) · <strong>Parallel</strong> ≈ max(entity).
                </div>
              </div>

              <div class="content-card" style="padding: 16px; display: flex; flex-direction: column; justify-content: center;">
                <h4 style="margin: 0 0 12px 0;">Tail amplification (intuition)</h4>
                <div class="math-note" style="margin: 0;">
                  P(≥1 slow) = 1 − (1 − p)<sup>n</sup>
                </div>
                <p style="margin: 12px 0 0 0; font-size: 14px; line-height: 1.6;">
                  With <strong>n ≈ 30</strong> lookups per request, even a small per-lookup slow rate <strong>p</strong>
                  becomes visible at the request level.
                </p>
              </div>
            </div>

            <div style="display: grid; grid-template-columns: 2fr 3fr; gap: 24px; margin-top: 16px;">
              <!-- Left: Success Criteria (smaller) -->
              <div class="content-card" style="display: flex; flex-direction: column; justify-content: center; padding: 20px;">
                <h3 style="margin: 0 0 12px 0; font-size: 17px;">Success criteria</h3>
                <ul class="bullets" style="font-size: 14px;">
                  <li><strong>P99</strong> stays within the serving SLO for the target hot/cold mix.</li>
                  <li><strong>Scales safely</strong> with bin-packing and parallelism without tail collapse.</li>
                  <li><strong>Worst-case is explicit</strong>: cold-read regimes are measured, not assumed.</li>
                </ul>
              </div>

              <!-- Right: 2x2 KPI grid (larger) -->
              <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 16px;">
                <div class="kpi">
                  <div class="kpi-label">Request fan-out</div>
                  <div class="kpi-value">~30</div>
                  <div class="kpi-sub">single-row lookups per request</div>
                </div>
                <div class="kpi">
                  <div class="kpi-label">Entities / request</div>
                  <div class="kpi-value">3</div>
                  <div class="kpi-sub">independent hot/cold</div>
                </div>
                <div class="kpi">
                  <div class="kpi-label">Access pattern</div>
                  <div class="kpi-value">SELECT *</div>
                  <div class="kpi-sub">LIMIT 1 point lookup</div>
                </div>
                <div class="kpi">
                  <div class="kpi-label">Traffic model</div>
                  <div class="kpi-value">Zipf</div>
                  <div class="kpi-sub">hot/cold matrix sweep</div>
                </div>
              </div>
            </div>
          </div>

          <!-- Right: integrated charts + narrative -->
          <div class="content-card" style="padding-bottom: 16px;">
            <h3>Key findings</h3>
            <p style="margin-top: 6px;">
              The goal is to understand which serving strategy best controls the <strong>request-level tail</strong>
              under fan-out—especially when reads are cold.
            </p>

            <!-- Sidebar layout: Question buttons left, Charts right -->
            <div style="display: grid; grid-template-columns: 280px 1fr; gap: 20px; margin-top: 16px;">
              
              <!-- Left: Question buttons (vertical) -->
              <div style="display: flex; flex-direction: column; gap: 12px;">
                <button class="chart-btn active" onclick="switchChartTab('chart1', this)" style="background: var(--surface-2); border: 2px solid var(--brand-2); border-radius: var(--radius-sm); padding: 16px; text-align: left; cursor: pointer; transition: all 0.3s ease; width: 100%;">
                  <div style="font-size: 11px; color: var(--brand-2); font-weight: 700; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 0.05em;">Overview</div>
                  <div style="font-size: 13px; color: var(--text); line-height: 1.4; font-weight: 500;">Mode Comparison (Serial vs Binpacked vs Parallel)</div>
                </button>
                
                <button class="chart-btn" onclick="switchChartTab('chart2', this)" style="background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-sm); padding: 16px; text-align: left; cursor: pointer; transition: all 0.3s ease; width: 100%;">
                  <div style="font-size: 11px; color: var(--brand-2); font-weight: 700; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 0.05em;">Question 1</div>
                  <div style="font-size: 13px; color: var(--muted); line-height: 1.4; font-weight: 500;">What is tail latency by serving strategy?</div>
                </button>
                
                <button class="chart-btn" onclick="switchChartTab('chart3', this)" style="background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-sm); padding: 16px; text-align: left; cursor: pointer; transition: all 0.3s ease; width: 100%;">
                  <div style="font-size: 11px; color: var(--brand-2); font-weight: 700; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 0.05em;">Question 2</div>
                  <div style="font-size: 13px; color: var(--muted); line-height: 1.4; font-weight: 500;">How does tail move as the hot fraction changes?</div>
                </button>
                
                <button class="chart-btn" onclick="switchChartTab('chart4', this)" style="background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-sm); padding: 16px; text-align: left; cursor: pointer; transition: all 0.3s ease; width: 100%;">
                  <div style="font-size: 11px; color: var(--brand-2); font-weight: 700; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 0.05em;">Question 3</div>
                  <div style="font-size: 13px; color: var(--muted); line-height: 1.4; font-weight: 500;">How much fan-out do we remove (measured queries/request)?</div>
                </button>
                
                <button class="chart-btn" onclick="switchChartTab('chart5', this)" style="background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-sm); padding: 16px; text-align: left; cursor: pointer; transition: all 0.3s ease; width: 100%;">
                  <div style="font-size: 11px; color: var(--brand-2); font-weight: 700; margin-bottom: 6px; text-transform: uppercase; letter-spacing: 0.05em;">Question 4</div>
                  <div style="font-size: 13px; color: var(--muted); line-height: 1.4; font-weight: 500;">How often does "≥1 slow lookup" happen per request?</div>
                </button>
              </div>

              <!-- Right: Chart panels (full width) -->
              <div class="chart-panel active" id="chart1">
              <div class="chart-frame" style="margin-top: 0; cursor: pointer;">
                <div class="chart-title">Mode Comparison: SLA Achievement</div>
                <div class="chart-note">Quick overview comparing Serial, Binpacked, and Parallel modes at 0% and 10% hot traffic (worst-case cold scenarios).</div>
                <div class="chart-content">
                  <img class="chart-embed" 
                    src="data:image/png;base64,{{CHART_EXEC_SLA_HEATMAP_BASE64}}"
                    alt="Mode Comparison SLA Heatmap"
                  />
                </div>
              </div>
            </div>

              <div class="chart-panel" id="chart2" style="display: none;">
                <div class="chart-frame" style="margin-top: 0; cursor: pointer;">
                  <div class="chart-title">Snapshot: tail latency by serving mode (P99 @ 0–20% hot)</div>
                  <div class="chart-note">Quick comparison of a cold-dominant regime where tail risk is highest.</div>
                  <div class="chart-content">
                    <img class="chart-embed" 
                      src="data:image/png;base64,{{CHART_EXEC_P99_COLD_POINTS_BASE64}}"
                      alt="Snapshot: tail latency by serving mode (P99 @ 0-20% hot)"
                    />
                  </div>
                </div>
              </div>

              <div class="chart-panel" id="chart3" style="display: none;">
                <div class="chart-frame" style="margin-top: 0; cursor: pointer;">
                  <div class="chart-title">P99 latency vs hot traffic %</div>
                  <div class="chart-note">How the request tail shifts as cacheability improves (hot fraction rises).</div>
                  <div class="chart-content">
                    <img class="chart-embed" 
                      src="data:image/png;base64,{{CHART_EXEC_P99_CURVES_BASE64}}"
                      alt="P99 latency vs hot traffic %"
                    />
                  </div>
                </div>
              </div>

              <div class="chart-panel" id="chart4" style="display: none;">
                <div class="chart-frame" style="margin-top: 0; cursor: pointer;">
                  <div class="chart-title">Queries per request by mode (measured)</div>
                  <div class="chart-note">Direct view of fan-out reduction from bin-packing (fewer round trips).</div>
                  <div class="chart-content">
                    <img class="chart-embed" 
                      src="data:image/png;base64,{{CHART_EXEC_QUERIES_PER_REQUEST_BASE64}}"
                      alt="Queries per request by mode"
                    />
                  </div>
                </div>
              </div>

              <div class="chart-panel" id="chart5" style="display: none;">
                <div class="chart-frame" style="margin-top: 0; cursor: pointer;">
                  <div class="chart-title">Probability of ≥1 slow query per request (tail amplification)</div>
                  <div class="chart-note">Connects per-query slowness to request-level tail under fan-out.</div>
                  <div class="chart-content">
                    <img class="chart-embed" 
                      src="data:image/png;base64,{{CHART_EXEC_TAIL_AMPLIFICATION_BASE64}}"
                      alt="Probability of ≥1 slow query per request"
                    />
                  </div>
                </div>
              </div>
            </div>

            <h3 style="margin-top: 20px;">What this enables</h3>
            <p style="margin: 0;">
              If Lakebase holds the request-level tail under this fan-out pattern, it can serve as a reliable online
              feature store layer while consolidating governance and analytics on the Databricks platform.
            </p>
          </div>
        </div>
      </div>
    </div>


    <!-- Tab: Workload Reality -->
    <!-- Tab: Workload Reality -->
    <div id="tab-workload-reality" class="tab-content">
      <!-- Hero -->
      <div class="card">
        <h2 class="section-title">Why this workload is hard</h2>
        <p class="section-subtitle">
          This is not a "single query latency test." It's a <b>request fan-out</b> test: one request triggers dozens of tiny
          lookups, and the <b>slowest lookup sets the tail</b>.
        </p>
      </div>

      <!-- Tight "what matters" strip -->
      <div class="content-grid three-col" style="margin-top: 8px; margin-bottom: 8px;">
        <div class="content-card" style="padding: 14px 16px;">
          <h3 class="card-title" style="margin-bottom: 4px; font-size: 14px;">1) Fan-out is the unit of pain</h3>
          <p class="card-body" style="margin-bottom: 0; font-size: 13px; line-height: 1.5;">
            Each request expands into <b>3 entities</b> and ~<b>30 table lookups</b>. Even "fast" lookups compound into slow requests when executed serially.
          </p>
        </div>

        <div class="content-card" style="padding: 14px 16px;">
          <h3 class="card-title" style="margin-bottom: 4px; font-size: 14px;">2) Tail amplification is math</h3>
          <p class="card-body" style="margin-bottom: 0; font-size: 13px; line-height: 1.5;">
            If each lookup has a small chance of being slow, the chance that <b>at least one</b> is slow becomes large at N≈30. That's why we care about <b>P99</b>.
          </p>
        </div>

        <div class="content-card" style="padding: 14px 16px;">
          <h3 class="card-title" style="margin-bottom: 4px; font-size: 14px;">3) Cold reads dominate serving</h3>
          <p class="card-body" style="margin-bottom: 0; font-size: 13px; line-height: 1.5;">
            Real-time fraud/payment decisions skew "cold" (unique keys), increasing cache-miss probability and making fan-out tails more frequent.
          </p>
        </div>
      </div>

      <!-- Main story row (diagram + math) -->
      <div class="content-grid two-col" style="margin-top: 8px;">
        <!-- Fan-out diagram -->
        <div class="content-card chart-card">
          <div class="chart-header">
            <h3>Request structure: a single request fans out</h3>
            <p>3 entities → multiple feature families × time windows → ~30 lookups</p>
          </div>

          <div class="math-callout" style="margin-top: 10px;">
            <div class="math-title">Fan-out cost model</div>
            <div class="math-body">
              <p style="margin: 0 0 10px;">
                Request latency depends on how many point reads compose a request.
              </p>
              <pre class="code-block" style="margin: 0 0 10px;"><code>Serial:   L_req ≈ Σ L_lookup      (fan-out accumulates)
Parallel: L_req ≈ max(L_entity)  (critical path dominates)</code></pre>
              <p style="margin: 0; font-size: 13px; opacity: 0.9;">
                With <b>N≈30</b>, variance inflates P99 → <b>bin-packing</b> (↓N) + <b>parallelism</b>.
              </p>
            </div>
          </div>

          <div class="chart-frame" style="margin-top: 12px;">
            <div class="chart-title">Lookup fan-out breakdown (what "30 lookups" actually means)</div>
            <img src="data:image/png;base64,{{CHART_FANOUT_BREAKDOWN_BASE64}}" alt="Lookup fan-out breakdown" class="chart-embed" />
            <div class="chart-caption">
              <b>Takeaway:</b> this workload punishes fan-out, not throughput. You can have spare CPU and still miss the SLO if
              request-level tails grow under cold reads.
            </div>
          </div>

          <div class="quote-block" style="margin-top: 12px;">
            <p class="quote">"In fan-out workloads, databases feel fast but requests don't."</p>
            <p class="quote-sub">Looking at single-query latency can be misleading: request latency is the composition of many tiny operations, and the tail is dominated by the slowest components.</p>
          </div>
        </div>

        <!-- Tail amplification math + visual -->
        <div class="content-card chart-card">
          <div class="chart-header">
            <h3>Tail amplification: why "rare" slow lookups dominate</h3>
            <p>Small per-lookup tail risk turns into frequent request spikes at N≈30</p>
          </div>

          <div class="math-callout" style="margin-top: 6px;">
            <div class="math-title">Intuition</div>
            <div class="math-body">
              <p style="margin: 0 0 8px;">
                If each lookup has probability <code>p</code> of being slow and a request performs <code>N</code> lookups:
              </p>
              <pre class="code-block" style="margin: 0 0 8px;"><code>P(≥1 slow) = 1 - (1 - p)^N</code></pre>
              <p style="margin: 0 0 10px; font-size: 13px; opacity: 0.9;">
                Example: <code>p=5%</code>, <code>N=30</code> → <b>78.5%</b> of requests have ≥1 slow lookup.
              </p>
              <p style="margin: 0; font-size: 14px; font-style: italic; opacity: 0.95; padding-top: 10px; border-top: 1px solid rgba(124,58,237,.2);">
                "In fan-out workloads, P99 is as much a probability metric as a performance metric."
              </p>
            </div>
          </div>

          <div class="chart-frame" style="margin-top: 8px;">
            <div class="chart-title">Tail amplification curve</div>
            <img src="data:image/png;base64,{{CHART_AMPLIFICATION_CURVE_BASE64}}" alt="Tail amplification curve" class="chart-embed" />
            <div class="chart-caption">
              <b>Takeaway:</b> Small improvements in per-lookup tail rate (p) produce large wins at request level.
              This motivates <b>bin-packing</b> (↓N) + <b>parallelism</b> (↓critical path).
            </div>
          </div>
        </div>
      </div>

      <!-- Cold reads row (tight + visual) -->
      <div class="content-grid two-col" style="margin-top: 8px;">
        <div class="content-card">
          <h3 class="card-title">Why cold reads make this worse</h3>
          <p class="card-body">
            Serving traffic often has weak locality: many requests touch "new" keys. That raises cache-miss probability and
            increases the frequency of request-level tail events.
          </p>

          <div class="grid" style="margin-top: 12px;">
            <div class="card" style="margin: 0; background: var(--surface-2);">
              <h4 style="font-size: 15px; margin-bottom: 8px; color: var(--brand-2);">Hot-key dominated (best case)</h4>
              <p style="font-size: 14px; color: var(--muted); margin: 0;">
                Many lookups hit cache → fewer tail events → fan-out is survivable.
              </p>
            </div>

            <div class="card" style="margin: 0; background: var(--surface-2);">
              <h4 style="font-size: 15px; margin-bottom: 8px; color: var(--warn);">Cold-read dominated (realistic)</h4>
              <p style="font-size: 14px; color: var(--muted); margin: 0;">
                Many lookups miss cache → tails become common → request P99 inflates quickly.
              </p>
            </div>
          </div>

          <div class="callout" style="margin-top: 12px; max-width: 100%;">
            <strong>Implication:</strong> validating performance at <b>0–20% hot</b> is essential for deployment confidence,
            not just at "mostly warm" cache conditions.
          </div>
        </div>

        <div class="content-card chart-card">
          <div class="chart-header">
            <h3>"How often is a request fully cold?"</h3>
            <p>A request is only as fast as its coldest entity</p>
          </div>

          <div class="chart-frame" style="margin-top: 6px;">
            <div class="chart-title">Expected request mix (0/1/2/3 hot entities) across hot%</div>
            <img src="data:image/png;base64,{{CHART_REQUEST_MIX_BASE64}}" alt="Request mix distribution" class="chart-embed" />
            <div class="chart-caption">
              <b>Takeaway:</b> how frequently the request must pay the cold path cost (disk + latency variance),
              which is the main driver of SLO risk in production serving.
            </div>
          </div>
        </div>
      </div>

      <!-- Bottom: bridge to next tabs -->
      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Key takeaway</div>
        <div class="takeaway-body">
          The benchmark is built around a realistic request shape (fan-out) and a realistic access pattern (cold-read heavy).
          Next, we show how the benchmark design makes this credible (Benchmark Design), then quantify P99 vs hot% (Results - Latency).
        </div>
      </div>
    </div>
    <!-- Tab: Benchmark Design -->
    <div id="tab-benchmark-design" class="tab-content">
      <div class="card">
        <p class="eyebrow">Benchmark Design</p>
        <h2 class="section-title">Benchmark design (how we make this defensible)</h2>
        <p class="section-subtitle">
          The goal here is credibility: <b>results that engineers trust</b> and EMs can defend.
          We intentionally model the serving workload the way it actually behaves in production:
          many small lookups, heavy cache skew, and strict tail latency expectations.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">1) Key sampling (avoiding "first N keys" bias)</h3>
          <p class="card-body">
            Many benchmarks accidentally sample "easy keys" due to storage order or biased table access patterns.
            We explicitly prevent that by sampling keys across <b>all tables in each entity fanout</b>.
          </p>

          <div class="code-callout">
            <div class="code-title">Random key sampling across all tables</div>
            <pre class="code-block"><code>def fetch_sample_keys(conn, table, limit):
    cur.execute(f"""
        SELECT DISTINCT hash_key
        FROM {SCHEMA}.{table}
        TABLESAMPLE SYSTEM (1)
        LIMIT %s
    """, (limit,))
    keys = [r[0] for r in cur.fetchall()]

    # fallback if TABLESAMPLE yields too few keys
    if len(keys) &lt; limit * 0.8:
        cur.execute(f"""
            SELECT DISTINCT hash_key
            FROM {SCHEMA}.{table}
            ORDER BY RANDOM()
            LIMIT %s
        """, (limit,))
        keys = [r[0] for r in cur.fetchall()]
    return keys</code></pre>
          </div>

          <div class="chart-caption">
            <b>Why this matters:</b> it prevents sampling bias that would understate P99
            (e.g., repeatedly querying keys clustered in cache-friendly regions).
          </div>

          <div class="insight-box">
            <div class="insight-title">Reproducibility</div>
            <div class="insight-body">
              Keys are persisted per-run so the hot/cold sets are consistent across modes (serial vs bin-packed vs parallel),
              enabling fair comparisons.
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">2) Zipfian hot/cold traffic matrix (workload realism)</h3>
          <p class="card-body">
            Real serving traffic is not uniform. It is <b>skewed</b>:
            some identities are hot, many are cold. We model this by sweeping hot% from fully warm to fully cold.
          </p>

          <div class="mini-metrics">
            <div class="mini-metric">
              <div class="metric-name">Hot/cold sweep</div>
              <div class="metric-desc">
                We test a matrix of hot% values to reveal "cliff behavior" as cache effectiveness drops.
              </div>
            </div>
            <div class="mini-metric">
              <div class="metric-name">Independent per entity</div>
              <div class="metric-desc">
                Each request independently chooses hot/cold per entity (realistic mixed-cache behavior).
              </div>
            </div>
            <div class="mini-metric">
              <div class="metric-name">True cold reads</div>
              <div class="metric-desc">
                At 0% hot we sample cold keys <b>without replacement</b> to prevent accidental cache warming.
              </div>
            </div>
          </div>

          <div class="code-callout">
            <div class="code-title">Independent hot/cold selection (per entity)</div>
            <pre class="code-block"><code>for entity in ENTITY_NAMES:
    if random.random() &lt; hot_pct / 100:
        hashkey = random.choice(entity_keys[entity]["hot"])
        hot_entities += 1
    else:
        hashkey = random.choice(entity_keys[entity]["cold"])</code></pre>
          </div>

          <div class="chart-caption">
            <b>Interpretation:</b> This gives us a latency curve (P99 vs hot%)
            that cleanly separates cache-dominated performance from disk/IO-dominated behavior.
          </div>
        </div>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">3) Realistic access pattern: <code>SELECT *</code> + <code>LIMIT 1</code></h3>
          <p class="card-body">
            To prevent "index-only illusion" benchmarks, we fetch real data.
            Serving systems typically need feature payload, not just existence checks.
          </p>

          <div class="code-callout">
            <div class="code-title">Measured query (production-like)</div>
            <pre class="code-block"><code>query = f"""
SELECT * 
FROM {SCHEMA}.{table}
WHERE hash_key = %s
LIMIT 1
"""
cur.execute(query, (hashkey,))
row = cur.fetchone()</code></pre>
          </div>

          <div class="insight-box">
            <div class="insight-title">What this ensures</div>
            <div class="insight-body">
              Measured latency includes tuple fetch cost, potential heap access, and payload transfer —
              not just index probe speed.
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">4) No inline EXPLAIN in the latency distribution</h3>
          <p class="card-body">
            Inline <code>EXPLAIN (ANALYZE, BUFFERS)</code> changes execution behavior and pollutes latency results.
            To keep the distribution clean, we measure latency using only the real query path.
          </p>

          <div class="mini-metrics">
            <div class="mini-metric">
              <div class="metric-name">Latency = real query path</div>
              <div class="metric-desc">No EXPLAIN contamination during the measured loop.</div>
            </div>
            <div class="mini-metric">
              <div class="metric-name">I/O via pg_statio</div>
              <div class="metric-desc">Reads/hits tracked at schema level for comparability.</div>
            </div>
            <div class="mini-metric">
              <div class="metric-name">Slow query log</div>
              <div class="metric-desc">Only slow queries are logged for later diagnosis.</div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">
              "We treat EXPLAIN as a diagnostic tool, not a measurement method."
            </p>
            <p class="quote-sub">
              This keeps our latency charts defensible to skeptics.
            </p>
          </div>
        </div>
      </div>

      <div class="content-card">
        <h3 class="card-title">Additional defensibility measures (V5.3)</h3>
        <div class="grid">
          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--brand-2);">Top-up key sampling</h4>
            <p style="font-size: 14px; color: var(--muted); margin-bottom: 8px;">
              If initial sampling yields too few unique keys (due to table overlap), we automatically 
              sample additional rounds until the target is met.
            </p>
            <div class="tag ok" style="margin-top: 8px;">Prevents underfill bias</div>
          </div>
          
          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--brand-2);">Pool wait tracking</h4>
            <p style="font-size: 14px; color: var(--muted); margin-bottom: 8px;">
              In parallel mode, we track connection acquisition time separately from query latency
              to detect pool starvation.
            </p>
            <div class="tag info" style="margin-top: 8px;">Diagnoses contention</div>
          </div>
          
          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--brand-2);">Schema migrations</h4>
            <p style="font-size: 14px; color: var(--muted); margin-bottom: 8px;">
              All results tables support <code>ALTER TABLE ... ADD COLUMN IF NOT EXISTS</code> 
              to handle schema evolution across benchmark versions.
            </p>
            <div class="tag ok" style="margin-top: 8px;">Forward compatible</div>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          The benchmark is built to be <b>hard to game</b> and easy to defend:
          realistic fan-out, realistic cache skew, real payload fetch, reproducible key sets, and clean tail latency measurements.
        </div>
      </div>
    </div>

    <!-- Tab: Results - Latency vs Hot Traffic % -->
    <div id="tab-results-latency-hot" class="tab-content">
      <div class="card">
        <p class="eyebrow">Results</p>
        <h2 class="section-title">Latency vs hot traffic % (what happens as cache fades)</h2>
        <p class="section-subtitle">
          This is the core output of the benchmark: <b>P99 latency as a function of cache skew</b>.
          A strong serving system doesn't just look good when everything is hot —
          it stays stable as the workload gets colder.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">P99 latency curve (hot% → cold%)</h3>
          <p class="card-body">
            The P99 curve shows how tail latency grows when fewer lookups hit memory.
            This reveals the "cache cliff" — the point where the system stops being memory-bound and becomes IO-bound.
          </p>

          <div class="chart-frame">
            <div class="chart-title">P99 latency vs hot traffic %</div>
            <div class="chart-placeholder" id="chart_p99_vs_hot_pct">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> overlay all modes (serial vs bin-packed vs parallel workers).</p>
              </div>
            </div>
            <div class="chart-caption">
              <b>How to interpret:</b>
              <ul class="bullets small">
                <li><b>Flat line</b> = robust to cold traffic</li>
                <li><b>Steep slope</b> = cache sensitivity (IO dominates)</li>
                <li><b>Parallel mode</b> should bend the curve down by shrinking critical path</li>
              </ul>
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">What "good" looks like</div>
            <div class="insight-body">
              A compelling result is not only "fast when hot" — it's <b>predictable when mixed</b>
              and <b>understandable when cold</b>.
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">Worst-case reality: cold request rate vs P99</h3>
          <p class="card-body">
            Hot% per entity does not translate linearly into request hotness.
            Because each request involves <b>multiple entities</b>, you get a distribution of:
            fully hot requests, fully cold requests, and mixed cases.
          </p>

          <div class="chart-frame">
            <div class="chart-title">Fully cold request rate vs P99 latency</div>
            <div class="chart-placeholder" id="chart_cold_rate_vs_p99">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> scatter or line chart: cold request rate → P99.</p>
              </div>
            </div>
            <div class="chart-caption">
              <b>Why this is powerful:</b> EMs care about the "worst-case rate", not just the average.
              Even if only 5% of traffic is fully cold, those requests define tail behavior and user experience risk.
            </div>
          </div>

          <div class="callout-card emphasis">
            <div class="callout-label">Key idea</div>
            <div class="callout-value">Mixed requests dominate reality</div>
            <div class="callout-footnote">
              The serving system must handle mixed hot/cold fan-out without collapsing P99.
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Executive interpretation: what the curves mean operationally</h3>
          <p class="card-body">
            These curves translate directly into production risk:
          </p>
          <ul class="bullets">
            <li>
              <b>If P99 rises sharply as hot% drops:</b> the system is cache-dependent and will be unstable under traffic shifts.
            </li>
            <li>
              <b>If P99 stays bounded as hot% drops:</b> you have headroom to absorb cold spikes, new tenants, or unseen identities.
            </li>
            <li>
              <b>If parallel improves P99 but flattens after N workers:</b> you've hit critical-path or contention limits (expected).
            </li>
          </ul>

          <div class="quote-block">
            <p class="quote">
              "This benchmark exposes the real question: how expensive is cold fan-out at P99?"
            </p>
            <p class="quote-sub">
              That is the deciding factor for replacing DynamoDB-like serving paths.
            </p>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          P99 vs hot% is the headline chart. It shows whether Lakebase stays stable when cache effectiveness declines —
          and whether bin-packing + parallelism meaningfully bends the tail curve.
        </div>
      </div>
    </div>

    <!-- Tab: What Dominates P99? -->
    <div id="tab-what-dominates-p99" class="tab-content">
      <div class="card">
        <p class="eyebrow">Results Deep-Dive</p>
        <h2 class="section-title">What dominates P99 latency?</h2>
        <p class="section-subtitle">
          P99 isn't "an average of all queries." It's typically driven by the slowest part of the request:
          a specific entity, table family, or rare cold-path behavior. This tab isolates what actually drives tail latency.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">Entity contribution at the tail</h3>
          <p class="card-body">
            Each request is composed of multiple entities (e.g., <b>card_fingerprint</b>, <b>customer_email</b>,
            <b>cardholder_name</b>). Even if each entity is "usually fast," the P99 tail is dominated by whichever entity
            most often becomes the critical path.
          </p>

          <div class="chart-frame">
            <div class="chart-title">Entity P99 contribution heatmap</div>
            <div class="chart-placeholder" id="chart_entity_p99_contribution_heatmap">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> Heatmap (% contribution) across hot% values.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>How to read:</b>
              <ul class="bullets small">
                <li><b>High % cells</b> = that entity dominates tail latency at that cache regime</li>
                <li><b>Shifts across hot%</b> reveal when IO-bound behavior moves between entity groups</li>
                <li><b>Stable dominance</b> suggests a structural issue (schema / indexing / table family)</li>
              </ul>
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">Why EMs care</div>
            <div class="insight-body">
              This is your optimization roadmap. You don't "optimize the system" — you optimize the <b>thing that dominates P99</b>.
              This turns the conversation from opinion to evidence.
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">Interpretation guide: typical dominance patterns</h3>
          <p class="card-body">
            When teams look at P99, the risk is "tuning everything." Instead, look for one of these patterns:
          </p>

          <div class="pattern-list">
            <div class="pattern-item">
              <div class="pattern-title">Pattern A — One entity dominates everywhere</div>
              <div class="pattern-body">
                Suggests schema/index design, payload width, or table family layout is driving tail.
                Optimize the dominant entity first before touching concurrency.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">Pattern B — Dominance shifts as hot% drops</div>
              <div class="pattern-body">
                Common when warm paths are evenly fast, but cold reads expose a particular entity's IO footprint.
                Cold-path tuning (cluster, caching, physical layout) yields outsized gains.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">Pattern C — Dominance increases under parallelism</div>
              <div class="pattern-body">
                If parallel improves average but one entity becomes the bottleneck, you've hit critical-path limits.
                This is expected: parallel turns "sum" into "max," revealing the slowest entity more clearly.
              </div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">
              "Parallelism doesn't remove the bottleneck — it makes the bottleneck obvious."
            </p>
            <p class="quote-sub">
              That's exactly what you want for an optimization plan.
            </p>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Optional: "table family dominance" view (next-level diagnosis)</h3>
          <p class="card-body">
            If you want to go deeper than entity-level dominance, group tables into families (e.g., <b>fraud_rates</b>,
            <b>time_since</b>, <b>good_rates</b>, <b>tesseract_velocities</b>) and compute tail contribution at that level.
            This is particularly strong when the question is: "Which feature families are too expensive to serve synchronously?"
          </p>

          <div class="chart-frame">
            <div class="chart-title">Table family contribution to slow queries (from slow query log)</div>
            <div class="chart-placeholder" id="chart_table_family_slow_query_share">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> Stacked bars: % of slow queries by table family.</p>
              </div>
            </div>
            <div class="chart-caption">
              <b>Why this is compelling:</b> it provides a "where to cut" answer (defer, precompute, denormalize, or cache)
              instead of just "things are slow."
            </div>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          P99 is dominated by a specific part of the request. Once you know which entity (and optionally which table family)
          dominates tail latency, optimization becomes targeted — and credibility improves immediately.
        </div>
      </div>
    </div>

    <!-- Tab: Bin-packing Efficiency -->
    <div id="tab-binpacking-efficiency" class="tab-content">
      <div class="card">
        <p class="eyebrow">Optimization</p>
        <h2 class="section-title">Bin-packing efficiency: fewer round trips, better tail</h2>
        <p class="section-subtitle">
          The serving workload is fan-out heavy. That means latency is often dominated by <b>per-query overhead</b>
          (network + planning + execution setup). Bin-packing reduces fan-out by collapsing many lookups into fewer queries.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">What is bin-packing (and why it helps)</h3>
          <p class="card-body">
            Within the same feature family (e.g., <b>fraud_rates</b>), tables across time windows (30d/90d/365d)
            share the same schema. We leverage that by issuing a single <code>UNION ALL</code> query per feature family.
          </p>

          <div class="code-callout">
            <div class="code-title">Bin-packed execution (one query per feature family)</div>
            <pre class="code-block"><code># group tables by feature type (fraud_rates, time_since, ...)
feature_groups = defaultdict(list)
for table in tables:
    feature_type = table.split("__")[-2]
    feature_groups[feature_type].append(table)

# execute 1 UNION ALL per group
union_parts = [
  f"(SELECT * FROM {SCHEMA}.{t} WHERE hash_key = %s LIMIT 1)"
  for t in group_tables
]
sql = " UNION ALL ".join(union_parts)
cur.execute(sql, [hashkey] * len(group_tables))</code></pre>
          </div>

          <div class="insight-box">
            <div class="insight-title">Expected impact</div>
            <div class="insight-body">
              Fewer round trips → less tail amplification risk → improved P99 stability.
              This is especially valuable when latency is "death by a thousand cuts."
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">Key metric: latency per query (cost-normalized)</h3>
          <p class="card-body">
            Comparing raw latency across modes is useful, but can be misleading if the number of queries changes.
            We include a normalized metric:
            <b>latency per query</b> = (request avg latency) ÷ (actual queries per request).
          </p>

          <div class="chart-frame">
            <div class="chart-title">Latency per query (serial vs bin-packed)</div>
            <div class="chart-placeholder" id="chart_latency_per_query">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> Show serial vs bin-packed at each hot%.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>How to interpret:</b>
              <ul class="bullets small">
                <li>If latency per query drops significantly → overhead (round trips/planning) was a major tail contributor</li>
                <li>If it doesn't drop much → IO dominates and query count reduction helps less than expected</li>
                <li>If bin-packed improves at warm but not cold → cold IO dominates and needs separate tuning</li>
              </ul>
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Transparency: actual query count reduction (measured, not assumed)</h3>
          <p class="card-body">
            We compute the actual number of executed queries per request rather than assuming a fixed number.
            In serial mode, this is the table fan-out. In bin-packed mode, it is the number of feature groups executed.
          </p>

          <div class="chart-frame">
            <div class="chart-title">Queries per request by mode (measured)</div>
            <div class="chart-placeholder" id="chart_queries_per_request">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> bar chart per mode + optional breakdown by entity.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>Compelling narrative:</b> "We didn't just make it faster — we reduced fan-out."
              That is the lever that improves tail reliability.
            </div>
          </div>

          <div class="callout-card emphasis">
            <div class="callout-label">Outcome</div>
            <div class="callout-value">Fan-out collapse reduces tail amplification</div>
            <div class="callout-footnote">
              Bin-packing reduces the number of opportunities for "one slow query" to blow up the request P99.
            </div>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          Bin-packing is a structural win: it reduces query count, improves cost-normalized efficiency,
          and makes the system less sensitive to fan-out tail amplification.
        </div>
      </div>
    </div>

    <!-- Tab: Parallelism - Diminishing Returns -->
    <div id="tab-parallelism-diminishing-returns" class="tab-content">
      <div class="card">
        <p class="eyebrow">Scaling Behavior</p>
        <h2 class="section-title">Parallelism: where it helps, where it stops helping</h2>
        <p class="section-subtitle">
          After bin-packing reduces fan-out, the next lever is parallel execution across entities.
          Parallelism can reduce request latency by turning <b>sum-of-entities</b> into <b>max-of-entities</b> —
          but it also introduces contention and a hard lower bound set by the slowest entity.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">The promise of parallelism</h3>
          <p class="card-body">
            In serial mode, each request pays the latency of all entities sequentially.
            In parallel mode, entities execute concurrently and the request latency becomes the critical path:
            <b>the slowest entity wins</b>.
          </p>

          <div class="math-callout">
            <div class="math-row">
              <span class="math-label">Serial:</span>
              <span class="math-expr">Request ≈ EntityA + EntityB + EntityC</span>
            </div>
            <div class="math-row">
              <span class="math-label">Parallel:</span>
              <span class="math-expr">Request ≈ max(EntityA, EntityB, EntityC)</span>
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">What this means in practice</div>
            <div class="insight-body">
              Parallelism is most valuable when entity latencies are similar (no clear bottleneck).
              If one entity dominates, parallelism helps initially — then plateaus quickly.
            </div>
          </div>

          <div class="code-callout">
            <div class="code-title">Parallel entity execution (bin-packed + workers)</div>
            <pre class="code-block"><code>with ThreadPoolExecutor(max_workers=num_workers) as executor:
    futures = [executor.submit(fetch_entity_worker, e, request_start)
               for e in entities_with_keys]
    for f in futures:
        entity, latency_ms, gantt_entry, queries_executed, pool_wait_ms = f.result()
        entity_timings[entity] = latency_ms

# request latency = critical path
request_latency_ms = max(entity_timings.values())</code></pre>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">Workers sweep: 1 → N</h3>
          <p class="card-body">
            We sweep worker counts to quantify scaling. The key question is not "can it go faster?" —
            it's "when do we stop getting meaningful returns per added worker?"
          </p>

          <div class="chart-frame">
            <div class="chart-title">P99 latency vs workers (diminishing returns)</div>
            <div class="chart-placeholder" id="chart_p99_vs_workers">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> show P99 at 80% hot across workers (1→4), plus optional 50% / 0% lines.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>How to read:</b>
              <ul class="bullets small">
                <li><b>Big drop from 1→2 workers</b> means entity parallelism is working</li>
                <li><b>Flattening beyond 2–3</b> suggests hitting the critical path or DB contention</li>
                <li><b>Regression at higher workers</b> indicates contention (pool waits, CPU, locks, IO)</li>
              </ul>
            </div>
          </div>

          <div class="chart-frame">
            <div class="chart-title">Pool wait time (contention indicator)</div>
            <div class="chart-placeholder" id="chart_pool_wait_time">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> show pool wait p95 across workers to reveal starvation/queuing.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>Why this matters:</b> if pool wait grows with workers, you're not accelerating work —
              you're increasing time spent waiting to start work.
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Why diminishing returns happens (the three usual culprits)</h3>

          <div class="pattern-list">
            <div class="pattern-item">
              <div class="pattern-title">1) Critical path limit</div>
              <div class="pattern-body">
                Once request latency ≈ slowest entity, adding workers can't push below that entity's P99.
                Fix requires optimizing the dominant entity (Tab 5), not adding more parallelism.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">2) Database contention</div>
              <div class="pattern-body">
                Higher concurrency increases contention for CPU, buffer cache, IO, and internal locks.
                If the database becomes the bottleneck, you see rising variance and weaker tail improvements.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">3) Client-side bottlenecks (pooling, scheduling)</div>
              <div class="pattern-body">
                If the connection pool is undersized or recycling too aggressively, workers spend time waiting.
                Pool wait time is the easiest way to prove this.
              </div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">"More workers isn't the strategy. Finding the plateau is the strategy."</p>
            <p class="quote-sub">
              The plateau tells you whether to invest next in parallelism, bin-packing, or the dominant entity's cold path.
            </p>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          Parallelism helps early, then plateaus. The plateau is valuable: it identifies whether your next step is
          deeper DB tuning, better pooling, or fixing the dominant entity that sets the critical path.
        </div>
      </div>
    </div>

    <!-- Tab: Overlap Visualization (Gantt) -->
    <div id="tab-overlap-gantt" class="tab-content">
      <div class="card">
        <p class="eyebrow">Visual Proof</p>
        <h2 class="section-title">Overlap visualization: serial "sum" vs parallel "max"</h2>
        <p class="section-subtitle">
          Numbers show outcomes — Gantt shows causality. This visualization makes the latency mechanics intuitive:
          serial execution stacks entity time, while parallel execution overlaps it.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">Serial execution: stacked time</h3>
          <p class="card-body">
            In serial mode, each entity executes after the previous one completes. Total request latency grows as
            the sum of entity latencies. This is where fan-out "punishes latency" most strongly.
          </p>

          <div class="chart-frame">
            <div class="chart-title">Gantt (Serial): entities executed sequentially</div>
            <div class="chart-placeholder" id="chart_gantt_serial">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> show 5–10 sample requests at a realistic hot% (e.g., 80%).</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>What this proves:</b> even small per-entity tail events compound because they are paid sequentially.
            </div>
          </div>

          <div class="code-callout">
            <div class="code-title">Serial timing capture (per entity)</div>
            <pre class="code-block"><code>entity_start = time.perf_counter()
# run entity tables (serial)
entity_end = time.perf_counter()

gantt_data.append({
  "entity": entity_name,
  "start_ms": (entity_start - request_start) * 1000,
  "end_ms": (entity_end - request_start) * 1000
})</code></pre>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">Parallel execution: overlapping work</h3>
          <p class="card-body">
            In parallel mode, entities overlap. Total request latency is driven by whichever entity finishes last.
            This reduces "sum" into "max" and exposes bottlenecks more clearly.
          </p>

          <div class="chart-frame">
            <div class="chart-title">Gantt (Parallel): entities overlap, critical path dominates</div>
            <div class="chart-placeholder" id="chart_gantt_parallel">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> same hot% and same sample size as serial for a clean visual contrast.</p>
              </div>
            </div>

            <div class="chart-caption">
              <b>How to interpret:</b> parallel reduces total time only when bars overlap meaningfully and are similar in length.
              The longest bar becomes the bottleneck.
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">This is the executive-friendly explanation</div>
            <div class="insight-body">
              Serial penalizes fan-out; parallel mitigates fan-out — but only until a single entity becomes dominant.
              That's the point where optimization becomes targeted (Tab 5) rather than "add more workers."
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Recommended "story" framing for the visual</h3>

          <div class="story-steps">
            <div class="story-step">
              <div class="step-number">1</div>
              <div class="step-body">
                <b>Show serial Gantt</b> to make "sum-of-entities" visually obvious.
              </div>
            </div>
            <div class="story-step">
              <div class="step-number">2</div>
              <div class="step-body">
                <b>Show parallel Gantt</b> to show overlap and introduce "max-of-entities."
              </div>
            </div>
            <div class="story-step">
              <div class="step-number">3</div>
              <div class="step-body">
                <b>Call out the longest bar</b> as "the bottleneck entity" and link to Tab 5.
              </div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">"Parallelism converts latency from 'stacked' to 'overlapped' — and reveals the bottleneck."</p>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          The Gantt view makes the benchmark mechanics undeniable: serial stacks latency, parallel overlaps it,
          and the critical path entity determines the floor. This is the cleanest bridge from results → action.
        </div>
      </div>
    </div>

    <!-- Tab: Tail Amplification -->
    <div id="tab-tail-amplification" class="tab-content">
      <div class="card">
        <p class="eyebrow">Tail Risk</p>
        <h2 class="section-title">Tail amplification: why fan-out punishes P99</h2>
        <p class="section-subtitle">
          P99 is rarely about average speed — it's about the probability that <b>at least one lookup goes slow</b>.
          With fan-out workloads, the request tail is amplified even if most queries are fast.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">The core idea (in one minute)</h3>
          <p class="card-body">
            A request fans out into multiple database lookups. Even if each lookup is "usually fast,"
            the request becomes slow whenever <b>any one</b> of those lookups lands in the tail.
          </p>

          <div class="math-callout">
            <div class="math-row">
              <span class="math-label">Probability request has ≥1 slow query:</span>
              <span class="math-expr">P(slow request) = 1 − (1 − p)<sup>n</sup></span>
            </div>
            <div class="math-note">
              where <b>p</b> = per-query probability of being "slow", and <b>n</b> = number of lookups per request
              (≈ 30 in serial; ≈ 9–12 effective groups with bin-packing; ≈ 3 entities on the critical path in parallel).
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">Executive interpretation</div>
            <div class="insight-body">
              This is why DynamoDB-style workloads are hard to beat on P99: the system is judged by worst-case lookup behavior,
              not throughput. Improving P99 is about reducing (a) per-lookup tail probability and/or (b) number of lookups.
            </div>
          </div>

          <div class="code-callout">
            <div class="code-title">Slow query instrumentation (what we persist)</div>
            <pre class="code-block"><code># Logged only if query_latency_ms >= SLOW_QUERY_THRESHOLD_MS
persist_query_timings(
  conn,
  run_id=RUN_ID,
  request_id=request_id,
  request_idx=i,
  fetch_mode=current_mode,
  parallel_workers=current_workers,
  hot_traffic_pct=hot_pct,
  query_timings=query_timings,         # entity/table/hash_key/latency_ms
  entity_hot_sets=entity_hot_sets,
  request_latency_ms=request_latency_ms # request context
)</code></pre>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">What we measure (not theorize)</h3>
          <p class="card-body">
            We log slow queries during the benchmark (above a fixed threshold). This enables:
            (1) measuring the observed slow-query rate, (2) estimating the probability of ≥1 slow query per request,
            and (3) comparing observed vs theoretical amplification.
          </p>

          <div class="chart-frame">
            <div class="chart-title">% of queries above slow threshold (by hot%)</div>
            <div class="chart-placeholder" id="chart_slow_query_rate">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> show slow-rate curve across hot% for serial & binpacked.</p>
              </div>
            </div>
            <div class="chart-caption">
              <b>What this tells you:</b> whether tail events are dominated by cold-path IO (steeper at low hot%)
              or systemic variability (flat even when hot% is high).
            </div>
          </div>

          <div class="chart-frame">
            <div class="chart-title">Probability of ≥1 slow query per request (tail amplification)</div>
            <div class="chart-placeholder" id="chart_prob_any_slow">
              <div class="placeholder-inner">
                <div class="placeholder-badge">Chart placeholder</div>
                <p><b>Recommended:</b> overlay theoretical amplification vs measured "slow request" rate.</p>
              </div>
            </div>
            <div class="chart-caption">
              <b>How to read:</b>
              <ul class="bullets small">
                <li>If measured ≈ theoretical → tail is driven by independent per-query variance</li>
                <li>If measured > theoretical → correlated slowdowns (contention, IO bursts, connection pool)</li>
                <li>If measured < theoretical → mitigation is working (bin-packing, cache locality, batching)</li>
              </ul>
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Why this is compelling (bridge from charts → action)</h3>

          <div class="pattern-list">
            <div class="pattern-item">
              <div class="pattern-title">Bin-packing reduces amplification</div>
              <div class="pattern-body">
                Fewer lookups means fewer chances for a tail event. This is the cleanest "math win" you can show.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">Parallelism reduces stacked tail</div>
              <div class="pattern-body">
                Parallelism prevents tail from compounding across sequential entities — but still leaves a critical-path tail.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">Dominant-entity optimization is the final lever</div>
              <div class="pattern-body">
                Once you reduce fan-out and add overlap, the bottleneck becomes whichever entity drives the critical path (Tab 5).
                That's where targeted schema/index/storage optimizations matter most.
              </div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">"In fan-out workloads, P99 isn't a performance metric — it's a probability metric."</p>
            <p class="quote-sub">
              The benchmark makes that probability measurable and actionable.
            </p>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Tab takeaway</div>
        <div class="takeaway-body">
          We don't just report P99 — we explain it. The slow-query log quantifies tail events and shows how bin-packing and
          parallelism reduce tail amplification. This turns the results into a defensible migration argument.
        </div>
      </div>
    </div>

    <!-- Tab: Recommendations & Next Steps -->
    <div id="tab-recommendations-next-steps" class="tab-content">
      <div class="card">
        <p class="eyebrow">Decision</p>
        <h2 class="section-title">Recommendations & next steps</h2>
        <p class="section-subtitle">
          The goal of this work is not "a fast benchmark." It's to establish a credible path to replacing DynamoDB-style
          feature serving with Lakebase — with an evidence-based plan for what to do next.
        </p>
      </div>

      <div class="content-grid two-col">
        <div class="content-card">
          <h3 class="card-title">What works now (based on measured behavior)</h3>

          <div class="recommendation-stack">
            <div class="rec-item">
              <div class="rec-title">1) Use bin-packing as the default</div>
              <div class="rec-body">
                It reduces request fan-out dramatically (30 table lookups → ~10 union groups), which directly reduces tail amplification.
                This is the "highest ROI" lever because it improves both average and tail without changing infrastructure.
              </div>
            </div>

            <div class="rec-item">
              <div class="rec-title">2) Add entity-level parallelism — but stop at the plateau</div>
              <div class="rec-body">
                Parallelism helps early by converting stacked latency into overlapped latency (Tab 8),
                but diminishing returns arrive quickly once the critical-path entity dominates (Tab 7).
              </div>
            </div>

            <div class="rec-item">
              <div class="rec-title">3) Treat P99 as a probability problem</div>
              <div class="rec-body">
                Use slow-query logging (Tab 9) to quantify tail risk and track whether improvements reduce
                slow event probability (<b>p</b>) or fan-out (<b>n</b>).
              </div>
            </div>
          </div>

          <div class="insight-box">
            <div class="insight-title">How to frame this to EMs</div>
            <div class="insight-body">
              "We identified the levers that reduce P99 for fan-out workloads: reduce lookups, overlap what remains,
              and then optimize the bottleneck entity's cold path."
            </div>
          </div>
        </div>

        <div class="content-card">
          <h3 class="card-title">What to improve next (priority-ordered)</h3>

          <div class="pattern-list">
            <div class="pattern-item">
              <div class="pattern-title">A) Server-side prepare / plan stability</div>
              <div class="pattern-body">
                If planning time is non-trivial (or fluctuates), prepare statements or stabilize query shapes.
                This is most relevant once query count drops (bin-packed) because planning becomes a larger fraction.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">B) Connection management: pool sizing + reuse</div>
              <div class="pattern-body">
                If pool wait increases with workers, you're bottlenecked client-side.
                Tune max_size, lifetime, and health checks. Track pool wait p95 as a leading indicator.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">C) Targeted bottleneck optimization (dominant entity)</div>
              <div class="pattern-body">
                Use the "What dominates P99?" analysis (Tab 5) to optimize the entity/table family that drives the critical path:
                indexing, clustering, table layout, row width, toast behavior, and cold-path IO.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">D) Payload discipline (row width + projection)</div>
              <div class="pattern-body">
                If payload bytes are high, implement column projection (model_projection mode).
                This reduces IO and CPU per lookup and often improves tail.
              </div>
            </div>

            <div class="pattern-item">
              <div class="pattern-title">E) Async IO / pipelining (if app architecture allows)</div>
              <div class="pattern-body">
                If the serving tier can pipeline requests (async DB clients, batched dispatch), you can increase overlap
                beyond simple thread pools — but only after controlling tail amplification via bin-packing.
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="content-grid one-col">
        <div class="content-card">
          <h3 class="card-title">Operational next steps (to make this "production real")</h3>

          <div class="ops-grid">
            <div class="ops-item">
              <div class="ops-title">Sizing & cost</div>
              <div class="ops-body">
                Use <b>latency per query</b> and <b>queries per request</b> as cost-normalized metrics (Tab 6).
                Then map to CU sizing assumptions and target QPS.
              </div>
            </div>

            <div class="ops-item">
              <div class="ops-title">HA/DR posture</div>
              <div class="ops-body">
                Define RTO/RPO requirements and validate failover behavior under sustained read QPS and mixed hot/cold traffic.
              </div>
            </div>

            <div class="ops-item">
              <div class="ops-title">Production monitoring</div>
              <div class="ops-body">
                Track request P99, per-entity latencies, slow query rate, pool wait p95, and cache hit/read ratios.
                These align directly with the benchmark's causal model.
              </div>
            </div>

            <div class="ops-item">
              <div class="ops-title">Safety checks</div>
              <div class="ops-body">
                Guardrails: statement timeouts, retry policy, backpressure, and well-defined fallback behavior
                for partial entity failures.
              </div>
            </div>
          </div>

          <div class="quote-block">
            <p class="quote">"The benchmark already tells us what to do next: reduce n, overlap the remainder, then fix the bottleneck."</p>
            <p class="quote-sub">
              If we follow this path, Lakebase becomes a credible replacement for DynamoDB-style fan-out serving.
            </p>
          </div>
        </div>
      </div>

      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Final takeaway</div>
        <div class="takeaway-body">
          We now have a defensible methodology and a clear optimization roadmap. The benchmark doesn't just measure latency —
          it explains P99 mechanics and points directly to the next engineering actions that will move the tail.
        </div>
      </div>
    </div>

    <!-- Tab: Overview -->
    <div id="tab-overview" class="tab-content">

<div class="card">
  <h2>Executive Summary</h2>
  <p style="color: var(--muted); margin-bottom: 14px;">
    This report answers a single question: <strong>Can Lakebase meet Checkout-style feature-serving SLAs under predominantly cold-read traffic?</strong>
    We benchmark a realistic payment-transaction workload (3 entities → ~30 point reads) across three execution strategies (serial, bin-packed, and parallel),
    and compare directly against the <strong>79ms P99</strong> production reference.
  </p>

  <div class="grid">
    <div class="card" style="margin:0">
      <h3>Problem statement</h3>
      <ul class="list">
        <li><strong>Serving shape:</strong> Fan-out reads across many small feature tables per request.</li>
        <li><strong>Traffic reality:</strong> Mostly unique transactions → <strong>0–20% hot</strong> per entity is the dominant operating regime.</li>
        <li><strong>Goal:</strong> Hit <strong>P99 ≤ 79ms</strong> without relying on measurement artifacts (e.g., EXPLAIN) or biased key selection.</li>
      </ul>
    </div>

    <div class="card" style="margin:0">
      <h3>What to believe (measurement hygiene)</h3>
      <ul class="list">
        <li><strong>No EXPLAIN contamination:</strong> All measured iterations are pure <code>SELECT *</code> point reads.</li>
        <li><strong>Defensible key sampling:</strong> Keys sampled across <em>all</em> tables per entity, deduped, shuffled, persisted.</li>
        <li><strong>Cold-read rigor:</strong> 0% hot uses <strong>no-replacement</strong> cold sampling to avoid accidental warming.</li>
      </ul>
    </div>
  </div>

  <div class="callout" style="margin-top: 14px; max-width: 100%;">
    <strong>How to read the report:</strong> Start with the summary table (0% and 10% hot),
    then use the charts to explain <em>why</em> a mode wins (round-trips, overlap, pool wait, and tail drivers).
  </div>
</div>

      <div class="card">
        <h2>Performance Summary - Production Traffic (0-10% Hot)</h2>
        <p style="color: var(--muted); margin-bottom: 20px;">
          <strong>Realistic for payment transactions:</strong> Each transaction is typically unique (different customer, card, merchant). 
          Hot keys are rare—most reads are cold or warm at best. This table shows performance at <strong>0% and 10% hot traffic</strong>, 
          representing worst-case cold scenarios.
        </p>
        
        <table>
          <thead>
            <tr>
              <th>Mode</th>
              <th>Workers</th>
              <th>Hot %</th>
              <th>P99 (ms)</th>
              <th>P95 (ms)</th>
              <th>Avg (ms)</th>
              <th>Queries/Req</th>
              <th>vs 79ms Target</th>
            </tr>
          </thead>
          <tbody id="summaryTable">
            {{SUMMARY_TABLE_ROWS}}
          </tbody>
        </table>
      </div>

<div class="card">
  <h2>How the Results Connect to the Method</h2>
  <div class="grid">
    <div class="card" style="margin:0">
      <h3>Round-trips vs compute</h3>
      <p>If <strong>bin-packed</strong> improves P99, the workload is dominated by network/round-trip overhead — typical for “many tiny reads”.</p>
    </div>
    <div class="card" style="margin:0">
      <h3>Overlap vs contention</h3>
      <p>If <strong>parallel</strong> improves P99 further, latency is per-entity and can be overlapped. If it regresses, check <strong>pool wait</strong> and connection limits.</p>
    </div>
    <div class="card" style="margin:0">
      <h3>Tail drivers</h3>
      <p>Use the slow query log + entity heatmap to answer: “Is P99 driven by one entity/table or tail amplification across many reads?”</p>
    </div>
  </div>
</div>

      
      <div class="grid">
        <div class="card">
          <h3>Key Findings (Cold-Read Focus)</h3>
          <ul class="list">
            <li>{{FINDING_1}}</li>
            <li>{{FINDING_2}}</li>
            <li>{{FINDING_3}}</li>
          </ul>
          <div class="callout" style="margin-top: 16px; max-width: 100%;">
            <strong>Why 0-20% hot?</strong> Payment transactions are rarely repeated within cache TTL. 
            Each request typically involves unique customer/card/merchant combinations.
          </div>
        </div>
        
        <div class="card">
          <h3>What This Benchmark Is</h3>
          <ul class="list">
            <li><span class="tag ok">Is</span> Cold-read latency benchmark for payment feature serving</li>
            <li><span class="tag ok">Is</span> Reproducible (persisted keys, no-replacement sampling)</li>
            <li><span class="tag ok">Is</span> Multi-mode comparison (serial, binpacked, parallel)</li>
            <li><span class="tag warn">Not</span> End-to-end app benchmark (DB layer only)</li>
            <li><span class="tag warn">Not</span> Throughput benchmark (latency-focused)</li>
          </ul>
        </div>
      </div>
      
      <div class="card">
        <h2>Full Results by Hot Traffic %</h2>
        <p style="color: var(--muted); margin-bottom: 16px;">
          Complete dataset across all cache scenarios (0%, 20%, 50%, 80%, 100% hot). 
          For Checkout.com's payment workload, <strong>focus on 0-20% rows</strong>—higher hot% scenarios 
          are included for comparison and sensitivity analysis only.
        </p>
        <details open>
          <summary>All mode/hot% combinations</summary>
          <table style="margin-top:12px">
            <thead>
              <tr>
                <th>Mode</th>
                <th>Workers</th>
                <th>Hot %</th>
                <th>P50</th>
                <th>P95</th>
                <th>P99</th>
                <th>Avg</th>
                <th>Cache Score</th>
                <th>IO Blocks</th>
              </tr>
            </thead>
            <tbody id="fullResultsTable">
              {{FULL_RESULTS_TABLE_ROWS}}
            </tbody>
          </table>
        </details>
      </div>
    </div>

    <!-- Tab: Request Model -->
    <div id="tab-request-model" class="tab-content">
      <div class="card">
        <h2>Workload Shape: What One Request Looks Like</h2>
        <p style="color: var(--muted); margin-bottom: 20px;">
          Each request queries <strong>3 entities</strong>. Each entity fans out to <strong>9–12 tables</strong> (~30 point reads total).
          Hot/cold choice is <strong>independent per entity</strong> to create realistic mixed-cache requests.
        </p>

<div class="callout" style="margin: 16px 0 6px; max-width: 100%;">
  <strong>What this implies for results:</strong> With 3 entities, “fully cold” requests happen naturally even at moderate hot rates.
  Expect the P99 curve to be dominated by the cold path unless hot% is very high.
</div>

        
        <div class="diagram">
          <!-- ✅ SVG Diagram from original template -->
          <svg viewBox="0 0 980 220" width="100%" height="220" role="img" aria-label="Request fanout diagram">
            <defs>
              <linearGradient id="g1" x1="0" x2="0" y1="0" y2="1">
                <stop offset="0" stop-color="rgba(124,58,237,.4)"/>
                <stop offset="1" stop-color="rgba(0,212,255,.3)"/>
              </linearGradient>
              <linearGradient id="g2" x1="0" x2="0" y1="0" y2="1">
                <stop offset="0" stop-color="rgba(0,255,136,.35)"/>
                <stop offset="1" stop-color="rgba(192,255,0,.25)"/>
              </linearGradient>
              <filter id="glow">
                <feGaussianBlur stdDeviation="3" result="coloredBlur"/>
                <feMerge>
                  <feMergeNode in="coloredBlur"/>
                  <feMergeNode in="SourceGraphic"/>
                </feMerge>
              </filter>
            </defs>

            <!-- Request -->
            <rect x="20" y="70" rx="14" ry="14" width="170" height="80" fill="url(#g1)" stroke="rgba(124,58,237,.8)" stroke-width="2" filter="url(#glow)"/>
            <text x="105" y="105" text-anchor="middle" fill="#ffffff" font-size="14" font-weight="700">Request</text>
            <text x="105" y="125" text-anchor="middle" fill="#c0ff00" font-size="12">3 entities</text>

            <!-- Entities -->
            <rect x="260" y="20" rx="14" ry="14" width="200" height="60" fill="rgba(26,26,26,.9)" stroke="rgba(0,212,255,.6)" stroke-width="2"/>
            <text x="360" y="50" text-anchor="middle" fill="#ffffff" font-size="13" font-weight="700">card_fingerprint</text>
            <text x="360" y="67" text-anchor="middle" fill="#a0a0a0" font-size="11">9 tables</text>

            <rect x="260" y="85" rx="14" ry="14" width="200" height="60" fill="rgba(26,26,26,.9)" stroke="rgba(0,212,255,.6)" stroke-width="2"/>
            <text x="360" y="115" text-anchor="middle" fill="#ffffff" font-size="13" font-weight="700">customer_email</text>
            <text x="360" y="132" text-anchor="middle" fill="#a0a0a0" font-size="11">9 tables</text>

            <rect x="260" y="150" rx="14" ry="14" width="200" height="60" fill="rgba(26,26,26,.9)" stroke="rgba(0,212,255,.6)" stroke-width="2"/>
            <text x="360" y="180" text-anchor="middle" fill="#ffffff" font-size="13" font-weight="700">cardholder_name</text>
            <text x="360" y="197" text-anchor="middle" fill="#a0a0a0" font-size="11">12 tables</text>

            <!-- Fanout -->
            <rect x="540" y="38" rx="14" ry="14" width="420" height="144" fill="url(#g2)" stroke="rgba(0,255,136,.7)" stroke-width="2" filter="url(#glow)"/>
            <text x="750" y="70" text-anchor="middle" fill="#ffffff" font-size="14" font-weight="700">Per-entity fanout</text>
            <text x="750" y="95" text-anchor="middle" fill="#e0e0e0" font-size="12">Serial: ~30 point reads total</text>
            <text x="750" y="118" text-anchor="middle" fill="#e0e0e0" font-size="12">Bin-packed: ~10 UNION ALL groups</text>
            <text x="750" y="141" text-anchor="middle" fill="#e0e0e0" font-size="12">Parallel: entities concurrent, critical path = max()</text>

            <!-- Arrows with glow -->
            <path d="M190 110 C220 110, 230 50, 260 50" fill="none" stroke="rgba(124,58,237,.9)" stroke-width="3" filter="url(#glow)"/>
            <path d="M190 110 C220 110, 230 115, 260 115" fill="none" stroke="rgba(0,212,255,.9)" stroke-width="3" filter="url(#glow)"/>
            <path d="M190 110 C220 110, 230 180, 260 180" fill="none" stroke="rgba(255,45,141,.9)" stroke-width="3" filter="url(#glow)"/>

            <path d="M460 50 C500 50, 510 110, 540 110" fill="none" stroke="rgba(0,255,136,.9)" stroke-width="3" filter="url(#glow)"/>
            <path d="M460 115 C500 115, 510 110, 540 110" fill="none" stroke="rgba(192,255,0,.9)" stroke-width="3" filter="url(#glow)"/>
            <path d="M460 180 C500 180, 510 110, 540 110" fill="none" stroke="rgba(0,255,136,.9)" stroke-width="3" filter="url(#glow)"/>
          </svg>
        </div>
        
        <details open>
          <summary>Code: entity fanout definition</summary>
          <pre><code># Entity → tables fanout
ENTITY_TABLE_GROUPS = {
  "card_fingerprint": [... 9 tables ...],
  "customer_email": [... 9 tables ...],
  "cardholder_name": [... 12 tables ...],
}
ENTITY_NAMES = list(ENTITY_TABLE_GROUPS.keys())</code></pre>
        </details>
        
        <div class="callout">
          <strong>Latency semantics:</strong> Serial mode measures "application-style" latency (sum of entity latencies).
          Parallel mode measures "critical path" latency (max of entity latencies).
        </div>
      </div>
      
      <div class="card">
        <h2>Independent Hot/Cold Per Entity</h2>
        <div class="callout" style="margin-bottom: 20px; max-width: 100%;">
          <strong>Production Context:</strong> For Checkout.com's payment workload, most reads are <strong>cold (0-20% hot)</strong>. 
          We still test higher hot% scenarios (50%, 80%, 100%) for <strong>sensitivity analysis</strong> and to understand 
          cache impact if workload patterns change.
        </div>
        <p>Each entity independently chooses hot or cold based on <code>hot_pct</code> probability:</p>
        
        <pre><code>for entity in ENTITY_NAMES:
    tables = ENTITY_TABLE_GROUPS[entity]
    keyset = entity_keys[entity]
    
    if random.random() < hot_pct / 100:
        hashkey = random.choice(keyset["hot"])
        hot_entities += 1
    else:
        hashkey = random.choice(keyset["cold"])
    
    entities_for_request.append({
        "entity": entity,
        "hashkey": hashkey,
        "tables": tables
    })</code></pre>
        
        <div class="callout">
          <strong>Why this is realistic:</strong> Real traffic has mixed cache state - one entity can be hot while another is cold.
          "Fully hot" and "fully cold" requests emerge naturally from independent sampling.
        </div>
      </div>
    </div>

    <!-- Tab: Key Sampling -->
    <div id="tab-key-sampling" class="tab-content">
      <div class="card">
        <h2>Key Sampling That's Defensible (and Reproducible)</h2>
        <p>The benchmark samples keys from <strong>all tables per entity</strong>, dedupes them into a pool of unique keys,
        randomly shuffles, and then splits into hot/cold sets. Keys are persisted per run for reproducibility.</p>

<div class="callout" style="margin: 14px 0; max-width: 100%;">
  <strong>Why EMs should care:</strong> If “hot keys” are biased (e.g., first-N in storage order), the benchmark overstates cache performance.
  This sampling method keeps the win/loss narrative grounded in production reality.
</div>

        
        <h3>V5.3: Top-Up Sampling Algorithm</h3>
        <pre><code>keys_set = set()
sampled_total = 0

for sampling_round in range(max_sampling_rounds):
    if len(keys_set) >= TOTAL_KEYS_PER_ENTITY:
        break
        
    for table in tables:
        if len(keys_set) >= TOTAL_KEYS_PER_ENTITY:
            break
            
        sample_size = keys_per_table if sampling_round == 0 else keys_per_table // 2
        table_keys = fetch_sample_keys(conn, table, sample_size)
        
        sampled_total += len(table_keys)
        before = len(keys_set)
        keys_set.update(table_keys)  # Dedupe
        new_unique = len(keys_set) - before

keys = list(keys_set)
duplication_ratio = sampled_total / len(keys) if len(keys) > 0 else 1.0
random.shuffle(keys)

# Safe hot/cold split (ensures non-empty sets)
hot_cutoff = int(len(keys) * HOT_KEY_PERCENT / 100)
hot_cutoff = max(hot_cutoff, 1)                # At least 1 hot key
hot_cutoff = min(hot_cutoff, len(keys) - 1)    # At least 1 cold key

entity_keys[entity] = {
    "hot": keys[:hot_cutoff],
    "cold": keys[hot_cutoff:]
}</code></pre>
      </div>
      
      <div class="card">
        <h2>Sampling Helper: TABLESAMPLE + Fallback</h2>
        <pre><code>def fetch_sample_keys(conn, table, limit):
    with conn.cursor() as cur:
        # Fast path: TABLESAMPLE SYSTEM (works well on large tables)
        cur.execute(f"""
            SELECT DISTINCT hash_key
            FROM {SCHEMA}.{table}
            TABLESAMPLE SYSTEM (1)
            LIMIT %s
        """, (limit,))
        keys = [r[0] for r in cur.fetchall()]
        
        # Fallback: ORDER BY RANDOM() if TABLESAMPLE under-returns
        if len(keys) < limit * 0.8:
            cur.execute(f"""
                SELECT DISTINCT hash_key
                FROM {SCHEMA}.{table}
                ORDER BY RANDOM()
                LIMIT %s
            """, (limit,))
            keys = [r[0] for r in cur.fetchall()]
    return keys</code></pre>
        
        <div class="callout">
          <strong>Why sampling from all tables matters:</strong> Sampling from a single table (or in storage order) can drastically bias "hot" keys.
          Dedupe + shuffle makes the hot/cold sets representative of the entity's full keyspace.
        </div>
      </div>
      
      <div class="card">
        <h2>Reproducibility: Persisted Keys + Metadata</h2>
        <ul class="list">
          <li>Keys are written to <code>features.zipfian_keys_per_run</code> keyed by <code>run_id</code></li>
          <li>Sampling metadata written to <code>features.zipfian_keys_run_meta</code>:
            <ul style="margin-top:8px">
              <li><code>target_keys_per_entity</code> - Target unique keys per entity</li>
              <li><code>sampled_keys_total_all_entities</code> - Total sampled across all entities</li>
              <li><code>sampled_keys_unique_all_entities</code> - Unique after dedupe</li>
              <li><code>duplication_ratio</code> - Indicates table overlap</li>
            </ul>
          </li>
          <li>Runs can reuse a previous keyset via <code>reuse_run_id</code> widget</li>
        </ul>
      </div>
    </div>

    <!-- Tab: Execution Modes -->
    <div id="tab-execution-modes" class="tab-content">
      <div class="card">
        <h2>Execution Modes: What Changes and What Doesn't</h2>
        <p>We test three execution strategies while keeping request shape and key distribution constant.
        This isolates the effect of query packing and concurrency.</p>
        
        <table>
          <thead>
            <tr>
              <th>Mode</th>
              <th>SQL Strategy</th>
              <th>Latency Calculation</th>
              <th>Purpose</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>serial</strong></td>
              <td>~30 individual SELECT statements</td>
              <td>SUM(entity_latencies)</td>
              <td>Baseline "application-style" fanout</td>
            </tr>
            <tr>
              <td><strong>binpacked</strong></td>
              <td>~10 UNION ALL grouped queries</td>
              <td>SUM(entity_latencies)</td>
              <td>Reduce round-trips via server-side batching</td>
            </tr>
            <tr>
              <td><strong>binpacked_parallel</strong></td>
              <td>Entities fetched concurrently (pool)</td>
              <td>MAX(entity_latencies) + pool_wait</td>
              <td>Async serving model (critical path)</td>
            </tr>
          </tbody>
        </table>

<div class="callout" style="margin-top: 12px; max-width: 100%;">
  <strong>How to pick a mode:</strong>
  If <em>bin-packed</em> lowers P99, you’re round-trip bound. If <em>parallel</em> lowers P99 further, you’re latency bound per-entity and can overlap work.
  If parallel doesn’t help (or gets worse), look at <strong>pool wait</strong> and DB connection limits.
</div>

      </div>
      
      <div class="grid">
        <div class="card">
          <h3>Mode A — Serial Baseline</h3>
          <p>30 single-table queries per request. Measures "naïve app" latency.</p>
          <pre><code>query = f"SELECT * FROM {SCHEMA}.{table} WHERE hash_key = %s LIMIT 1"
cur.execute(query, (hashkey,))
row = cur.fetchone()</code></pre>
        </div>
        
        <div class="card">
          <h3>Mode B — Bin-Packed (Serial)</h3>
          <p>Tables with identical schemas are UNION ALL'd into feature groups. Typically ~3–4 queries per entity.</p>
          <pre><code># Example: fraud_rates__30d/90d/365d → 1 query
sql = " UNION ALL ".join(
  f"(SELECT * FROM {SCHEMA}.{t} WHERE hash_key = %s LIMIT 1)"
  for t in group_tables
)
cur.execute(sql, [hashkey] * len(group_tables))
rows = cur.fetchall()</code></pre>
        </div>
      </div>
      
      <div class="card">
        <h3>Mode C — Bin-Packed + Parallel Entities</h3>
        <p>Entities run concurrently with a connection pool. Request latency approximates critical path (max entity latency) plus any pool wait.</p>
        
        <pre><code>with ThreadPoolExecutor(max_workers=num_workers) as ex:
    futures = [ex.submit(fetch_entity_worker, e, request_start)
               for e in entities_for_request]
    
    for f in futures:
        entity, latency_ms, gantt, q_count, pool_wait_ms = f.result()
        entity_timings[entity] = latency_ms
        pool_wait_times.append(pool_wait_ms)

request_latency_ms = max(entity_timings.values())</code></pre>
        
        <div class="callout">
          <strong>Pool wait tracking:</strong> V5.3 captures connection acquisition time to detect pool starvation.
          High pool wait can dominate P99 and indicate undersized pool or DB connection limits.
        </div>
      </div>
    </div>

    <!-- Tab: Timing & Logging -->
    <div id="tab-timing" class="tab-content">
      <div class="card">
        <h2>Timing, Slow-Query Logging, and Tail Diagnosis</h2>
        <p>We measure per-entity latency, capture Gantt-friendly timing segments, and log slow queries (≥ threshold) 
        for post-run investigation.</p>
        
        <h3>Per-Entity Timing (Not Cumulative)</h3>
        <pre><code>entity_start = time.perf_counter()

for table in entity_tables:
    t0 = time.perf_counter()
    cur.execute("SELECT * FROM ... WHERE hash_key=%s LIMIT 1", (hashkey,))
    cur.fetchone()
    q_ms = (time.perf_counter() - t0) * 1000
    
    if log_query_timings and q_ms >= SLOW_QUERY_THRESHOLD_MS:
        query_timings.append({
            "entity": entity,
            "table": table,
            "latency_ms": q_ms,
            "query_type": "single_select",
            "query_group": None
        })

entity_ms = (time.perf_counter() - entity_start) * 1000
entity_timings[entity] = entity_ms</code></pre>
      </div>
      
      <div class="card">
        <h2>V5.3: Production-Grade Measurement Hygiene</h2>
        
        <h3>✅ No Inline EXPLAIN</h3>
        <p>All measured iterations execute <strong>pure SELECT queries</strong>. EXPLAIN is reserved for post-run diagnostics on logged slow queries.</p>
        <div class="callout">
          <strong>Why:</strong> EXPLAIN (ANALYZE, BUFFERS) perturbs latency and can distort tail behavior.
          We log "what was slow" and run EXPLAIN post-run on those samples to keep the measured distribution clean.
        </div>
        
        <h3>✅ No VACUUM Between Modes</h3>
        <p>Previously VACUUM ANALYZE was <strong>warming buffers</strong> instead of flushing. V5.3 uses only:</p>
        <pre><code>def flush_cache(conn):
    # DISCARD ALL: Clear session state
    with conn.cursor() as cur:
        cur.execute("DISCARD ALL")
        conn.commit()
    
    time.sleep(2)  # Short cooldown</code></pre>
        
        <h3>✅ Pool Wait Tracking (Parallel Mode)</h3>
        <pre><code>pool_wait_start = time.perf_counter()
with pool.connection() as conn:
    pool_wait_ms = (time.perf_counter() - pool_wait_start) * 1000
    
    if pool_wait_ms > 100:
        print(f"⚠️  Slow pool acquisition: {pool_wait_ms:.0f}ms")</code></pre>
        
        <h3>✅ Slow Query Log (Full Schema)</h3>
        <p>Queries ≥40ms are logged to <code>zipfian_slow_query_log</code> with:</p>
        <ul class="list">
          <li><code>query_type</code> - 'single_select' or 'union_group'</li>
          <li><code>query_group</code> - Feature group name for binpacked (e.g., 'fraud_rates')</li>
          <li><code>request_latency_ms</code> - Total request latency for tail attribution</li>
          <li><code>parallel_workers</code> - Worker count for parallel mode</li>
        </ul>
      </div>
    </div>

    <!-- Tab: I/O Measurement -->
    <div id="tab-io" class="tab-content">
      <div class="card">
        <h2>I/O Measurement Strategy</h2>
        <p>For serial mode, we use <code>pg_statio_user_tables</code> as an aggregate signal of buffer hits vs reads
        over the benchmark window.</p>
        
        <h3>pg_statio Aggregate Approach</h3>
        <pre><code>def read_pg_io_stats(conn):
    cur.execute("""
        SELECT COALESCE(SUM(heap_blks_read),0) AS reads,
               COALESCE(SUM(heap_blks_hit),0)  AS hits
        FROM pg_statio_user_tables
        WHERE schemaname = %s
    """, (SCHEMA,))
    return cur.fetchone()

reset_pg_stats(conn)  # Requires elevated privileges
before_reads, before_hits = read_pg_io_stats(conn)

# ... run benchmark ...

after_reads, after_hits = read_pg_io_stats(conn)
io_blocks_read = after_reads - before_reads
io_blocks_per_req = io_blocks_read / ITERATIONS_PER_RUN</code></pre>
      </div>
      
      <div class="card">
        <h2>Interpretation Notes</h2>
        <ul class="list">
          <li><strong>Not perfect, still useful:</strong> pg_statio is aggregate and schema-wide, but trends are informative</li>
          <li><strong>Permissions:</strong> <code>pg_stat_reset()</code> may fail without elevated privileges; code falls back gracefully</li>
          <li><strong>Bin-packed modes:</strong> I/O per request is not computed by default (UNION ALL complicates attribution)</li>
          <li><strong>Alternative:</strong> Post-run EXPLAIN on sampled slow queries gives precise per-query I/O</li>
        </ul>
        
        <div class="callout">
          <strong>V5.3 improvement:</strong> We removed inline EXPLAIN to prevent contamination.
          I/O measurement for serial mode now relies purely on pg_statio aggregate, which is cleaner and faster.
        </div>
      </div>
    </div>

    <!-- Tab: Results Deep-Dive -->
    <div id="tab-results" class="tab-content">
      <div class="card">
        <h2>Detailed Performance Breakdown</h2>
        <p style="color: var(--muted); margin-bottom: 20px;">
          Comprehensive view of all benchmark runs. Use this to understand <strong>why</strong> a mode wins or loses,
          and to identify bottlenecks (round-trips, per-query overhead, pool contention).
        </p>
      </div>

      <div class="card">
        <h2>Mode Performance Matrix (All Hot % Scenarios)</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Full results across all execution modes and cache scenarios. 
          <strong>Reminder:</strong> For Checkout.com workload, focus on <code>hot_pct = 0</code> and <code>hot_pct = 20</code>.
        </p>
        
        <table>
          <thead>
            <tr>
              <th>Mode</th>
              <th>Workers</th>
              <th>Hot %</th>
              <th>P50 (ms)</th>
              <th>P95 (ms)</th>
              <th>P99 (ms)</th>
              <th>Avg (ms)</th>
              <th>Queries/Req</th>
              <th>Latency/Query</th>
              <th>Cache Score</th>
            </tr>
          </thead>
          <tbody id="detailedResultsTable">
            {{DETAILED_RESULTS_TABLE_ROWS}}
          </tbody>
        </table>
        
        <div class="callout" style="margin-top: 16px; max-width: 100%;">
          <strong>How to read this:</strong>
          <ul class="list" style="margin-top: 8px; text-align: left;">
            <li><strong>Latency/Query:</strong> Lower is better. If binpacked has lower latency/query than serial, round-trips dominate.</li>
            <li><strong>P99 vs Avg gap:</strong> Large gap indicates tail amplification (some requests hit slow paths).</li>
            <li><strong>Cache Score:</strong> Fraction of entities that hit hot keys (0.0 = all cold, 1.0 = all hot).</li>
          </ul>
        </div>
      </div>

      <div class="card">
        <h2>Tail Analysis: What's Slow?</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Top 10 slowest queries logged during the benchmark. These are candidates for optimization or explain plans.
        </p>
        
        <details open>
          <summary>Slowest Queries (≥40ms threshold)</summary>
          <table style="margin-top: 12px;">
            <thead>
              <tr>
                <th>Entity</th>
                <th>Table/Group</th>
                <th>Latency (ms)</th>
                <th>Query Type</th>
                <th>Hot Key?</th>
                <th>Request Latency (ms)</th>
              </tr>
            </thead>
            <tbody id="slowQueriesTable">
              {{SLOW_QUERIES_TABLE_ROWS}}
            </tbody>
          </table>
        </details>
        
        <div class="callout" style="margin-top: 16px; max-width: 100%;">
          <strong>What to look for:</strong>
          <ul class="list" style="margin-top: 8px; text-align: left;">
            <li>If most slow queries are <code>union_group</code> type, UNION ALL overhead may be significant.</li>
            <li>If slow queries cluster on one entity, that entity has a hot spot or data distribution issue.</li>
            <li>If <code>Hot Key? = false</code> dominates, the workload is truly cold-read bound (expected for Checkout.com).</li>
          </ul>
        </div>
      </div>

      <div class="card">
        <h2>Per-Entity Contribution to P99</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Which entity dominates tail latency? Useful for prioritizing optimization efforts.
        </p>
        
        <table>
          <thead>
            <tr>
              <th>Entity</th>
              <th>Table Count</th>
              <th>P99 Contribution (ms)</th>
              <th>Avg Contribution (ms)</th>
              <th>% of Total P99</th>
            </tr>
          </thead>
          <tbody id="entityContributionTable">
            {{ENTITY_CONTRIBUTION_TABLE_ROWS}}
          </tbody>
        </table>
        
        <div class="callout" style="margin-top: 16px; max-width: 100%;">
          <strong>Interpretation:</strong> If one entity contributes >50% of P99, it's the bottleneck. 
          If contributions are balanced, tail is driven by aggregate fanout across all entities.
        </div>
      </div>

      <div class="card">
        <h2>Parallel Mode Analysis (Workers = 2, 4, 8)</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Concurrency effectiveness: Does adding workers reduce latency, or do we hit pool/connection limits?
        </p>
        
        <table>
          <thead>
            <tr>
              <th>Workers</th>
              <th>Hot %</th>
              <th>P99 (ms)</th>
              <th>vs Serial P99</th>
              <th>Speedup</th>
              <th>Pool Wait P99 (ms)</th>
              <th>Status</th>
            </tr>
          </thead>
          <tbody id="parallelAnalysisTable">
            {{PARALLEL_ANALYSIS_TABLE_ROWS}}
          </tbody>
        </table>
        
        <div class="callout" style="margin-top: 16px; max-width: 100%;">
          <strong>Red flags:</strong>
          <ul class="list" style="margin-top: 8px; text-align: left;">
            <li><strong>Pool Wait P99 > 10ms:</strong> Connection pool is undersized or DB connection limit reached.</li>
            <li><strong>Speedup < 1.2x:</strong> Parallelism isn't helping—could be serial bottleneck or contention.</li>
            <li><strong>P99 increases with workers:</strong> Pool starvation or DB-side queueing.</li>
          </ul>
        </div>
      </div>

      <div class="card">
        <h2>Key Sampling Quality Check</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Defensibility: Did we sample keys fairly, or are results biased?
        </p>
        
        <table>
          <thead>
            <tr>
              <th>Entity</th>
              <th>Target Keys</th>
              <th>Sampled Total</th>
              <th>Unique Keys</th>
              <th>Duplication Ratio</th>
              <th>Hot/Cold Split</th>
              <th>Status</th>
            </tr>
          </thead>
          <tbody id="keySamplingTable">
            {{KEY_SAMPLING_TABLE_ROWS}}
          </tbody>
        </table>
        
        <div class="callout" style="margin-top: 16px; max-width: 100%;">
          <strong>What "good" looks like:</strong>
          <ul class="list" style="margin-top: 8px; text-align: left;">
            <li><strong>Duplication Ratio ≈ 1.0-1.5:</strong> Minimal overlap across tables (good diversity).</li>
            <li><strong>Unique Keys = Target:</strong> Sampling met its goal (no underfill).</li>
            <li><strong>Hot/Cold Split:</strong> Should match configured hot %.</li>
          </ul>
        </div>
      </div>

      <div class="card">
        <h2>Export & Reproduce</h2>
        <p style="color: var(--muted); margin-bottom: 12px;">
          Run ID and data access for reproducibility.
        </p>
        
        <details>
          <summary>SQL to reproduce this report's data</summary>
          <pre style="margin-top: 12px;"><code>-- Main results
SELECT * FROM features.zipfian_feature_serving_results_v5
WHERE run_id = '{{RUN_ID}}'
ORDER BY fetch_mode, parallel_workers NULLS FIRST, hot_traffic_pct;

-- Slow queries
SELECT * FROM features.zipfian_slow_query_log
WHERE run_id = '{{RUN_ID}}'
  AND hot_traffic_pct IN (0, 20)  -- Focus on cold reads
ORDER BY query_latency_ms DESC
LIMIT 50;

-- Key sampling metadata
SELECT * FROM features.zipfian_keys_run_meta
WHERE run_id = '{{RUN_ID}}';</code></pre>
        </details>
        
        <div style="margin-top: 16px; padding: 16px; background: rgba(0,212,255,.1); border: 1px solid rgba(0,212,255,.3); border-radius: 8px;">
          <p style="margin: 0; color: var(--brand-2); font-weight: 600;">
            🔗 Run ID: <code style="color: var(--text); background: rgba(0,212,255,.2);">{{RUN_ID}}</code>
          </p>
          <p style="margin: 8px 0 0; font-size: 13px; color: var(--muted);">
            All raw data is stored in <code>features.*</code> schema and can be queried directly for custom analysis.
          </p>
        </div>
      </div>
    </div>

    <!-- Tab: Charts -->
    <div id="tab-charts" class="tab-content">
      <div class="card">
        <h2>Benchmark Visualizations</h2>
        <p style="color: var(--muted); margin-bottom: 24px;">
          All charts auto-generated from run <strong>{{RUN_ID}}</strong> with review-approved fixes
        </p>
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>1. P99 Latency vs Access Skew</h3>
          <p>Mode-separated scatter plot with customer reference line</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART1_NARRATIVE_1}}</li>
    <li>{{CHART1_NARRATIVE_2}}</li>
    <li>{{CHART1_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_P99_SKEW_BASE64}}" alt="P99 vs Skew" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>2. Cost-Normalized Performance</h3>
          <p>Wall-clock latency per DB call (proves we're not "cheating" with batching)</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART2_NARRATIVE_1}}</li>
    <li>{{CHART2_NARRATIVE_2}}</li>
    <li>{{CHART2_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_COST_NORMALIZED_BASE64}}" alt="Cost Normalized" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>3. Concurrency Diminishing Returns</h3>
          <p>P50 + P99 vs parallel workers (with serial baseline)</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART3_NARRATIVE_1}}</li>
    <li>{{CHART3_NARRATIVE_2}}</li>
    <li>{{CHART3_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_CONCURRENCY_BASE64}}" alt="Concurrency" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>4. Gantt Timeline: Serial vs Parallel</h3>
          <p>Visual proof of overlap (30 queries serial vs 10 queries parallel, speedup annotated)</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART4_NARRATIVE_1}}</li>
    <li>{{CHART4_NARRATIVE_2}}</li>
    <li>{{CHART4_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_GANTT_BASE64}}" alt="Gantt" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>5. Entity Contribution Heatmap</h3>
          <p>Which entity dominates P99 at different hot/cold ratios</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART5_NARRATIVE_1}}</li>
    <li>{{CHART5_NARRATIVE_2}}</li>
    <li>{{CHART5_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_HEATMAP_BASE64}}" alt="Entity Heatmap" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>6. Fully Cold Request Probability</h3>
          <p>Math-backed curve showing tail amplification from multi-entity fanout</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART6_NARRATIVE_1}}</li>
    <li>{{CHART6_NARRATIVE_2}}</li>
    <li>{{CHART6_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_WORST_CASE_BASE64}}" alt="Worst Case" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>7. Cache Causality</h3>
          <p>Correlation between cache score and latency</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART7_NARRATIVE_1}}</li>
    <li>{{CHART7_NARRATIVE_2}}</li>
    <li>{{CHART7_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_CACHE_BASE64}}" alt="Cache" class="chart-embed" />
      </div>
      
      <div class="card chart-card">
        <div class="chart-header">
          <h3>8. I/O Amplification</h3>
          <p>Disk blocks read vs hot traffic %</p>
        </div>

<div class="card" style="margin: 12px 0 18px; background: rgba(26,26,26,.65); border-style: dashed;">
  <h3 style="margin-top: 0;">What this chart is telling you</h3>
  <ul class="list">
    <li>{{CHART8_NARRATIVE_1}}</li>
    <li>{{CHART8_NARRATIVE_2}}</li>
    <li>{{CHART8_NARRATIVE_3}}</li>
  </ul>
  <p style="color: var(--muted-2); font-size: 13px; margin-top: 8px;">
    <strong>Tip:</strong> Anchor on <code>0%</code> and <code>20%</code> hot first (production-like), then use higher hot% for sensitivity.
  </p>
</div>

        <img src="data:image/png;base64,{{CHART_IO_BASE64}}" alt="IO" class="chart-embed" />
      </div>
    </div>

    <!-- Tab: Appendix (Engineering Methodology) -->
    <div id="tab-appendix" class="tab-content">
      <div class="card">
        <p class="eyebrow">Appendix: Engineering Methodology</p>
        <h2 class="section-title">How the benchmark works (for internal engineers)</h2>
        <p class="section-subtitle">
          This appendix explains <b>what the code actually does</b>, with snippets and implementation details.
          Goal: defensible, reproducible, production-realistic latency measurement.
        </p>
      </div>

      <!-- Section 1: Request Construction -->
      <div class="content-card">
        <h3 class="card-title">1) Request shape: Multi-entity fan-out</h3>
        <p class="card-body">
          One "feature request" fetches <b>3 entities</b> (card_fingerprint, customer_email, cardholder_name), 
          each expanding to 9-12 feature tables. Serial baseline = <b>30 queries per request</b>.
        </p>

        <div class="code-frame">
          <div class="code-title">Core request builder (serial mode)</div>
          <pre class="code-block"><code class="language-python"># Build multi-entity request (independent hot/cold per entity)
for entity in ENTITY_NAMES:
    tables = ENTITY_TABLE_GROUPS[entity]
    keyset = entity_keys[entity]
    
    # Independently sample hot vs cold per entity
    if random.random() &lt; hot_pct / 100:
        hashkey = random.choice(keyset["hot"])
        hot_entities += 1
    else:
        hashkey = random.choice(keyset["cold"])
    
    entities_for_request.append({
        "entity": entity,
        "hashkey": hashkey,
        "tables": tables
    })</code></pre>
          <div class="code-caption">
            <b>Why this matters:</b> Each entity has independent cache state. At 80% hot per entity, 
            only 51% of requests are "fully hot" (0.8³). Mixed states dominate real traffic.
          </div>
        </div>

        <div class="metric-grid">
          <div class="metric-box">
            <div class="metric-label">Serial mode</div>
            <div class="metric-value">30 queries</div>
            <div class="metric-note">1 SELECT per table</div>
          </div>
          <div class="metric-box">
            <div class="metric-label">Binpacked mode</div>
            <div class="metric-value">10 queries</div>
            <div class="metric-note">UNION ALL per feature family</div>
          </div>
          <div class="metric-box">
            <div class="metric-label">Parallel mode</div>
            <div class="metric-value">10 queries</div>
            <div class="metric-note">Concurrent via ThreadPoolExecutor</div>
          </div>
        </div>
      </div>

      <!-- Section 2: Key Sampling -->
      <div class="content-card">
        <h3 class="card-title">2) Key sampling: Reproducible hot/cold sets</h3>
        <p class="card-body">
          Keys are sampled from <b>all tables per entity</b>, deduped, shuffled, then split 99:1 (hot:cold).
          Saved to <code>zipfian_keys_per_run</code> for run-to-run consistency.
        </p>

        <div class="code-frame">
          <div class="code-title">Sampling strategy (TABLESAMPLE + fallback)</div>
          <pre class="code-block"><code class="language-python">def fetch_sample_keys(conn, table, limit):
    # Fast path: TABLESAMPLE SYSTEM (probabilistic)
    cur.execute(f"""
        SELECT DISTINCT hash_key
        FROM {SCHEMA}.{table}
        TABLESAMPLE SYSTEM (1)
        LIMIT %s
    """, (limit,))
    keys = [r[0] for r in cur.fetchall()]
    
    # Fallback if under-sampled
    if len(keys) &lt; limit * 0.8:
        cur.execute(f"""
            SELECT DISTINCT hash_key
            FROM {SCHEMA}.{table}
            ORDER BY RANDOM()
            LIMIT %s
        """, (limit,))
        keys = [r[0] for r in cur.fetchall()]
    return keys

# Sample across ALL tables, dedupe, shuffle, split
keys_set = set()
for table in entity_tables:
    keys_set.update(fetch_sample_keys(conn, table, 5000))

keys = list(keys_set)
random.shuffle(keys)

hot_count = int(len(keys) * 0.99)
hot_keys = keys[:hot_count]
cold_keys = keys[hot_count:]</code></pre>
          <div class="code-caption">
            <b>Realism fix:</b> At 0% hot, use <i>no-replacement</i> sampling from cold set to force true cache misses.
          </div>
        </div>
      </div>

      <!-- Section 3: Execution Modes -->
      <div class="content-card">
        <h3 class="card-title">3) Execution modes: Serial → Binpacked → Parallel</h3>
        <p class="card-body">
          Three strategies with <b>identical request shape and keys</b>. Only query structure and execution pattern change.
        </p>

        <div class="grid">
          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--muted-2);">Serial (baseline)</h4>
            <div class="code-frame" style="margin: 12px 0;">
              <pre class="code-block" style="font-size: 12px; padding: 12px;"><code>for entity in entities:
    for table in entity["tables"]:
        SELECT * FROM {table}
        WHERE hash_key = %s</code></pre>
            </div>
            <p style="font-size: 13px; color: var(--muted); margin: 8px 0 0;">
              30 queries, sequential. Latency = Σ(query times).
            </p>
          </div>

          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--brand-2);">Binpacked</h4>
            <div class="code-frame" style="margin: 12px 0;">
              <pre class="code-block" style="font-size: 12px; padding: 12px;"><code>for entity in entities:
    for feature_family in families:
        SELECT * FROM table1
        WHERE hash_key = %s
        UNION ALL
        SELECT * FROM table2
        WHERE hash_key = %s</code></pre>
            </div>
            <p style="font-size: 13px; color: var(--muted); margin: 8px 0 0;">
              10 queries (UNION ALL). Reduces fan-out by 3×.
            </p>
          </div>

          <div class="card" style="margin: 0; background: var(--surface-2);">
            <h4 style="font-size: 15px; margin-bottom: 10px; color: var(--ok);">Parallel</h4>
            <div class="code-frame" style="margin: 12px 0;">
              <pre class="code-block" style="font-size: 12px; padding: 12px;"><code>with ThreadPoolExecutor(w=3) as pool:
    futures = []
    for entity in entities:
        future = pool.submit(
            fetch_entity_binpacked,
            entity
        )
        futures.append(future)
    results = [f.result() for f in futures]</code></pre>
            </div>
            <p style="font-size: 13px; color: var(--muted); margin: 8px 0 0;">
              10 queries, concurrent. Latency = max(entity times) + pool overhead.
            </p>
          </div>
        </div>
      </div>

      <!-- Section 4: Timing & Observability -->
      <div class="content-card">
        <h3 class="card-title">4) Timing measurement: Per-entity + Gantt-ready</h3>
        <p class="card-body">
          We capture <b>start/end timestamps per entity</b> to enable Gantt visualization and diagnose parallel overlap.
        </p>

        <div class="code-frame">
          <div class="code-title">Timing capture (parallel mode example)</div>
          <pre class="code-block"><code class="language-python">entity_timing_detail = []

for iteration in range(iterations):
    entities_for_request = build_request(entity_keys, hot_pct)
    
    iteration_detail = {
        "iteration": iteration,
        "entities": []
    }
    
    with ThreadPoolExecutor(max_workers=parallel_workers) as pool:
        futures = {}
        for entity_data in entities_for_request:
            start_time = time.perf_counter()
            future = pool.submit(fetch_entity_binpacked, conn, entity_data)
            futures[future] = (entity_data["entity"], start_time)
        
        for future in as_completed(futures):
            entity_name, start_ms = futures[future]
            end_ms = (time.perf_counter() - request_start) * 1000
            
            iteration_detail["entities"].append({
                "entity": entity_name,
                "start_ms": start_ms,
                "end_ms": end_ms
            })
    
    entity_timing_detail.append(iteration_detail)</code></pre>
          <div class="code-caption">
            <b>Stored as JSON:</b> Enables post-run Gantt chart generation showing entity overlap.
          </div>
        </div>

        <div class="callout" style="margin-top: 20px;">
          <strong>Slow query logging:</strong> Queries >40ms are logged to <code>zipfian_slow_query_log</code>
          with request_id tracing. Post-run EXPLAIN available for diagnosis.
        </div>
      </div>

      <!-- Section 5: I/O Measurement -->
      <div class="content-card">
        <h3 class="card-title">5) I/O measurement: Buffer hits vs disk reads</h3>
        <p class="card-body">
          For serial mode, we use <code>pg_statio_user_tables</code> as an aggregate signal of buffer hits vs reads.
        </p>

        <div class="code-frame">
          <div class="code-title">I/O delta calculation</div>
          <pre class="code-block"><code class="language-sql">-- Capture baseline I/O stats
SELECT 
    relname,
    heap_blks_read,
    heap_blks_hit
FROM pg_statio_user_tables
WHERE schemaname = 'features';

-- Run benchmark iterations...

-- Capture final I/O stats, compute delta
SELECT 
    SUM(heap_blks_read_after - heap_blks_read_before) AS total_blocks_read,
    SUM(heap_blks_hit_after - heap_blks_hit_before) AS total_blocks_hit
FROM io_stats_delta;</code></pre>
          <div class="code-caption">
            <b>Caveat:</b> I/O measurement is aggregate (not per-request). Used as directional signal for cache behavior.
          </div>
        </div>
      </div>

      <!-- Section 6: Results Storage -->
      <div class="content-card">
        <h3 class="card-title">6) Results tables: What gets saved</h3>
        <p class="card-body">
          All metrics are persisted to enable cross-run comparison and post-hoc analysis.
        </p>

        <div class="table-responsive">
          <table class="results-table">
            <thead>
              <tr>
                <th>Table</th>
                <th>Purpose</th>
                <th>Key columns</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><code>zipfian_feature_serving_results_v5</code></td>
                <td>Main results (one row per mode × hot%)</td>
                <td>run_id, fetch_mode, hot_traffic_pct, p99_ms, entity_p99_ms (JSON)</td>
              </tr>
              <tr>
                <td><code>zipfian_keys_per_run</code></td>
                <td>Persisted hot/cold key sets per entity</td>
                <td>run_id, entity, hot_keys (JSON), cold_keys (JSON)</td>
              </tr>
              <tr>
                <td><code>zipfian_slow_query_log</code></td>
                <td>Queries exceeding threshold (>40ms)</td>
                <td>run_id, request_id, table_name, query_latency_ms</td>
              </tr>
              <tr>
                <td><code>zipfian_explain_cache</code></td>
                <td>Post-run EXPLAIN results (optional)</td>
                <td>run_id, table_name, query_hash, explain_json</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-frame" style="margin-top: 20px;">
          <div class="code-title">Query recent runs</div>
          <pre class="code-block"><code class="language-sql">-- Compare P99 across modes at 50% hot
SELECT 
    run_id,
    fetch_mode,
    parallel_workers,
    p99_ms,
    avg_cache_score
FROM features.zipfian_feature_serving_results_v5
WHERE hot_traffic_pct = 50
ORDER BY run_ts DESC, fetch_mode, parallel_workers;</code></pre>
        </div>
      </div>

      <!-- Section 7: Defensibility Checklist -->
      <div class="content-card">
        <h3 class="card-title">7) Defensibility checklist</h3>
        <p class="card-body">
          What makes this benchmark credible for production evaluation?
        </p>

        <div class="checklist-grid">
          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">Real payload fetch</div>
              <div class="checklist-text">Uses <code>SELECT *</code> to include heap fetch + row materialization cost (not just index lookups)</div>
            </div>
          </div>

          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">Production key distribution</div>
              <div class="checklist-text">Keys sampled across ALL tables (not cherry-picked hot keys). Zipfian 99:1 split matches observed skew.</div>
            </div>
          </div>

          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">Independent entity cache state</div>
              <div class="checklist-text">Each entity samples hot/cold independently, creating realistic mixed cache scenarios.</div>
            </div>
          </div>

          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">Connection reuse + keepalive</div>
              <div class="checklist-text">Persistent connections with schema refresh to avoid connection overhead in measurements.</div>
            </div>
          </div>

          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">No inline EXPLAIN</div>
              <div class="checklist-text">Avoids query plan pollution. Optional post-run EXPLAIN for diagnosis.</div>
            </div>
          </div>

          <div class="checklist-item">
            <div class="checklist-icon">✓</div>
            <div class="checklist-content">
              <div class="checklist-title">Run-to-run reproducibility</div>
              <div class="checklist-text">Keys are persisted per run_id. Can reuse keys via <code>reuse_run_id</code> parameter.</div>
            </div>
          </div>
        </div>
      </div>

      <!-- Source Code Reference -->
      <div class="content-card">
        <h3 class="card-title">Source code reference</h3>
        <div class="reference-links">
          <div class="reference-item">
            <div class="reference-title">📄 Benchmark script</div>
            <div class="reference-path"><code>{{BENCHMARK_NOTEBOOK}}</code></div>
            <div class="reference-desc">Main benchmark implementation (V5.3)</div>
          </div>
          <div class="reference-item">
            <div class="reference-title">📊 Visualization script</div>
            <div class="reference-path"><code>{{VISUALS_NOTEBOOK}}</code></div>
            <div class="reference-desc">Chart generation and report builder</div>
          </div>
          <div class="reference-item">
            <div class="reference-title">🔧 Utility modules</div>
            <div class="reference-path"><code>utils/pipelined_load.py</code>, <code>utils/feature_server.py</code></div>
            <div class="reference-desc">Helper functions for parallel execution and data loading</div>
          </div>
        </div>
      </div>

      <!-- Takeaway -->
      <div class="takeaway-banner" style="margin-bottom: 0;">
        <div class="takeaway-title">Methodology takeaway</div>
        <div class="takeaway-body">
          This benchmark measures <b>request-level tail latency under realistic fan-out and cache skew</b>.
          Key design choices (SELECT *, independent entity sampling, no inline EXPLAIN) prioritize production fidelity over microbenchmark speed.
          All metrics are persisted and reproducible via run_id.
        </div>
      </div>
    </div>

  </div>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div style="display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 16px; margin-bottom: 16px;">
        <div>
          <p style="font-size: 14px; margin-bottom: 4px;">
            <strong style="color: var(--text);">Benchmark V5.3</strong> (Production-Grade)
          </p>
          <p style="font-size: 12px; color: var(--muted-2);">
            Generated: <strong id="timestamp">{{TIMESTAMP}}</strong>
          </p>
        </div>
        <div class="run-badge">
          <span>Run ID:</span> <strong id="runIdFooter">{{RUN_ID}}</strong>
        </div>
      </div>
      <div style="border-top: 1px solid var(--border); padding-top: 16px; font-size: 12px; color: var(--muted-2);">
        <p style="margin-bottom: 6px;">
          Benchmark: <code>/Users/som.natarajan@databricks.com/benchmark_zipfian_realistic_v5.3</code>
        </p>
        <p>
          Visualizations: <code>/Users/som.natarajan@databricks.com/zipfian_benchmark_visuals_with_report</code>
        </p>
      </div>
    </div>
  </footer>

  <!-- Modal for enlarged charts -->
  <div id="chartModal" class="chart-modal" onclick="closeChartModal()">
    <button class="chart-modal-close" onclick="closeChartModal()" aria-label="Close">×</button>
    <img id="chartModalImg" class="chart-modal-content" src="" alt="Enlarged chart" onclick="event.stopPropagation()">
  </div>

  <script>
    // Tab switching
    
function switchTab(tabName, el) {
  // Hide all tabs
  document.querySelectorAll('.tab-content').forEach(el2 => el2.classList.remove('active'));
  document.querySelectorAll('.tab').forEach(el2 => el2.classList.remove('active'));

  // Show selected tab
  document.getElementById('tab-' + tabName).classList.add('active');

  // Mark clicked tab as active (works for inline onclick + programmatic calls)
  if (el) el.classList.add('active');
}

// Chart button switching within Key Findings
function switchChartTab(chartId, el) {
  // Hide all chart panels
  document.querySelectorAll('.chart-panel').forEach(panel => panel.style.display = 'none');
  
  // Reset all buttons to inactive state
  document.querySelectorAll('.chart-btn').forEach(btn => {
    btn.style.background = 'var(--surface)';
    btn.style.border = '1px solid var(--border)';
    btn.classList.remove('active');
    // Set question text to muted
    const questionText = btn.querySelector('div:last-child');
    if (questionText) questionText.style.color = 'var(--muted)';
  });

  // Show selected chart panel
  document.getElementById(chartId).style.display = 'block';
  
  // Mark clicked button as active
  if (el) {
    el.style.background = 'var(--surface-2)';
    el.style.border = '2px solid var(--brand-2)';
    el.classList.add('active');
    // Set question text to white
    const questionText = el.querySelector('div:last-child');
    if (questionText) questionText.style.color = 'var(--text)';
  }
}

// Chart modal functions
function openChartModal(imgSrc) {
  const modal = document.getElementById('chartModal');
  const modalImg = document.getElementById('chartModalImg');
  modalImg.src = imgSrc;
  modal.classList.add('active');
  document.body.style.overflow = 'hidden';
}

function closeChartModal() {
  const modal = document.getElementById('chartModal');
  modal.classList.remove('active');
  document.body.style.overflow = '';
}

// Close modal on Escape key
document.addEventListener('keydown', function(e) {
  if (e.key === 'Escape') {
    closeChartModal();
  }
});

// Make all chart images clickable
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('.chart-embed').forEach(img => {
    img.addEventListener('click', function() {
      openChartModal(this.src);
    });
  });
});

  </script>

</body>
</html>
