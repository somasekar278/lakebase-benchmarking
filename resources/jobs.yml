# Jobs configuration for Databricks Asset Bundles
# Fraud feature benchmarking jobs

resources:
  jobs:
    # ALL 30 TABLES: 16.6B rows total
    fraud_all_tables:
      name: "[${bundle.target}] Full Load: All 30 Tables (16.6B rows)"
      description: "Load all 30 fraud feature tables with correct row counts"
      
      tasks:
        - task_key: generate_csvs
          description: "Task 1: Generate CSVs for all 30 tables"
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/load_schema_from_ddl.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_schema: ${var.lakebase_schema}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              ddl_file_path: "${workspace.file_path}/generated/fraud_feature_tables.sql"
              rows_per_table_file: "${workspace.file_path}/generated/fraud_tables_row_counts.txt"
              uc_volume_path: "/Volumes/${var.catalog}/${var.schema}/${var.volume}"
              csv_only: "true"
          
          timeout_seconds: 86400  # 24 hours
          max_retries: 0
        
        - task_key: pipelined_load
          description: "Task 2: Pipelined Load (COPY → INDEX → SWAP)"
          depends_on:
            - task_key: generate_csvs
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/run_pipelined_load.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_schema: ${var.lakebase_schema}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              uc_volume_path: "/Volumes/${var.catalog}/${var.schema}/${var.volume}"
          
          timeout_seconds: 86400  # 24 hours
          max_retries: 0
      
      max_concurrent_runs: 1
      
      tags:
        Environment: ${bundle.target}
        Project: fraud-benchmarking
        Type: production
      
      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}
    
    # ZIPFIAN MULTI-ENTITY BENCHMARK WITH VISUALIZATIONS (V3 - Production Grade)
    zipfian_benchmark_full:
      name: "[${bundle.target}] Zipfian Multi-Entity Benchmark V3 + Visualizations"
      description: "Run production-grade multi-entity Zipfian benchmark (100% → 0% hot traffic) with EXPLAIN sampling, error handling, and visualizations"
      
      tasks:
        - task_key: run_zipfian_benchmark
          description: "Task 1: Run Multi-Entity Zipfian Benchmark V3 (9 hot/cold ratios)"
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/benchmark_zipfian_realistic_v3.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_schema: ${var.lakebase_schema}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              iterations_per_run: "1000"
              total_keys_per_entity: "10000"
              hot_key_percent: "1"
              explain_sample_rate: "999999"
              run_all_modes: "true"
              fetch_mode: "serial"
              reuse_run_id: "8e5d19d6"
          
          libraries:
            - pypi:
                package: psycopg[binary,pool]
            - pypi:
                package: numpy
            - pypi:
                package: pandas
            - pypi:
                package: matplotlib
            - pypi:
                package: seaborn
          
          # No timeout - let it run as long as needed
          max_retries: 0
        
        - task_key: generate_visualizations
          description: "Task 2: Generate 7 Professional Visualizations"
          depends_on:
            - task_key: run_zipfian_benchmark
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/zipfian_benchmark_visuals.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              run_id: "latest"
          
          libraries:
            - pypi:
                package: psycopg[binary,pool]
            - pypi:
                package: numpy
            - pypi:
                package: pandas
            - pypi:
                package: matplotlib
            - pypi:
                package: seaborn
            - pypi:
                package: plotly
            - pypi:
                package: kaleido
          
          # No timeout - let it run as long as needed
          max_retries: 0
      
      max_concurrent_runs: 1
      timeout_seconds: 0  # CRITICAL: No timeout - let benchmark run as long as needed
      
      tags:
        Environment: ${bundle.target}
        Project: fraud-benchmarking
        Type: benchmark
      
      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}
    
    # RPC MODE MINI TEST (V5.4) - Quick 10-iteration validation
    rpc_mode_test:
      name: "[${bundle.target}] RPC Mode Mini Test (10 iterations)"
      description: "Quick test of rpc_request_json mode with 10 iterations + visualization"
      
      tasks:
        - task_key: run_rpc_benchmark
          description: "Task 1: Run RPC Mode Benchmark (10 iterations)"
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/benchmark_zipfian_realistic_v5.4.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_schema: ${var.lakebase_schema}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              fetch_mode: "rpc_request_json"
              run_all_modes: "false"
              iterations_per_run: "10"
              hot_key_percent: "1"
              log_query_timings: "false"
          
          libraries:
            - pypi:
                package: psycopg[binary,pool]
            - pypi:
                package: numpy
            - pypi:
                package: pandas
            - pypi:
                package: matplotlib
            - pypi:
                package: seaborn
          
          timeout_seconds: 1800  # 30 minutes max
          max_retries: 0
        
        - task_key: generate_visualizations
          description: "Task 2: Generate Visualizations with RPC Mode"
          depends_on:
            - task_key: run_rpc_benchmark
          existing_cluster_id: "0120-120746-h595w64t"
          
          notebook_task:
            notebook_path: ../notebooks/zipfian_benchmark_visuals.py
            base_parameters:
              lakebase_host: ${var.lakebase_host}
              lakebase_database: ${var.lakebase_database}
              lakebase_user: ${var.lakebase_user}
              lakebase_password: ${var.lakebase_password}
              run_id: "latest"
              results_table: "v5"
          
          libraries:
            - pypi:
                package: psycopg[binary,pool]
            - pypi:
                package: numpy
            - pypi:
                package: pandas
            - pypi:
                package: matplotlib
            - pypi:
                package: seaborn
            - pypi:
                package: plotly
            - pypi:
                package: kaleido
            - pypi:
                package: jinja2
          
          timeout_seconds: 1800  # 30 minutes max
          max_retries: 0
      
      max_concurrent_runs: 1
      
      tags:
        Environment: ${bundle.target}
        Project: fraud-benchmarking
        Type: test
        Mode: rpc_request_json
      
      email_notifications:
        on_failure:
          - ${workspace.current_user.userName}
        on_success:
          - ${workspace.current_user.userName}
