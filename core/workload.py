"""
Abstract base classes for Lakebase benchmark workloads.

Supports two modes:
1. Schema-defined: User specifies exact table structures (e.g., fraud detection)
2. Auto-generated: Framework generates N tables with M features (flexible benchmarking)
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from enum import Enum


class QueryStrategy(Enum):
    """Different query execution strategies"""
    SINGLE_TABLE = "single_table"           # Simple SELECT from one table
    MULTI_TABLE_JOIN = "multi_table_join"   # JOINs across tables
    BINPACKED_SP = "binpacked_sp"           # Stored procedure with multiple queries
    AGGREGATION = "aggregation"             # GROUP BY, aggregations
    FULL_TEXT_SEARCH = "full_text_search"   # Text search queries
    CUSTOM = "custom"                        # User-defined query


@dataclass
class TableDef:
    """Definition of a table for benchmarking"""
    name: str
    columns: Dict[str, str]  # column_name -> column_type
    rows: int
    primary_key: str = "primary_key"
    indexes: List[str] = None
    foreign_keys: Dict[str, str] = None  # column -> referenced_table.column
    
    def __post_init__(self):
        if self.indexes is None:
            self.indexes = []
        if self.foreign_keys is None:
            self.foreign_keys = {}


@dataclass
class QueryPattern:
    """Definition of a query pattern to benchmark"""
    name: str
    strategy: QueryStrategy
    query: Optional[str] = None              # SQL query (if CUSTOM)
    tables: List[str] = None                 # Tables involved
    keys_per_query: int = 1                  # How many keys to lookup
    description: str = ""
    
    # For binpacked stored procedures
    stored_procedure: Optional[str] = None   # SP name
    sp_params: Optional[Dict] = None         # SP parameters
    
    def __post_init__(self):
        if self.tables is None:
            self.tables = []
        if self.sp_params is None:
            self.sp_params = {}


class Workload(ABC):
    """
    Abstract base class for benchmark workloads.
    
    Users can either:
    1. Subclass this and define get_tables() / get_queries()
    2. Use AutoGeneratedWorkload for flexible benchmarking
    """
    
    def __init__(self, name: str = None, description: str = None):
        self.name = name or self.__class__.__name__
        self.description = description or ""
    
    @abstractmethod
    def get_tables(self) -> List[TableDef]:
        """
        Define the tables for this workload.
        
        Returns:
            List of TableDef objects
        """
        pass
    
    @abstractmethod
    def get_queries(self) -> List[QueryPattern]:
        """
        Define the query patterns to benchmark.
        
        Returns:
            List of QueryPattern objects
        """
        pass
    
    def get_baseline(self) -> Dict[str, float]:
        """
        Get baseline metrics for comparison (optional).
        
        Returns:
            Dict with 'p99', 'sla_target', etc.
        """
        return {
            'p99': None,
            'sla_target': 120,
        }
    
    def custom_metrics(self, results: Any) -> Dict[str, Any]:
        """
        Calculate custom metrics beyond standard latency (optional).
        
        Args:
            results: Benchmark results
            
        Returns:
            Dict of custom metrics
        """
        return {}
    
    def generate_stored_procedure(self) -> Optional[str]:
        """
        Generate stored procedure SQL for binpacking (optional).
        
        Returns:
            SQL string or None if not using binpacking
        """
        return None


class SchemaDefinedWorkload(Workload):
    """
    Workload where user defines exact table schemas.
    
    Example: Fraud detection with specific tables like fraud_reports_365d
    """
    
    def __init__(self, name: str, tables: List[TableDef], queries: List[QueryPattern], **kwargs):
        super().__init__(name=name, **kwargs)
        self._tables = tables
        self._queries = queries
    
    def get_tables(self) -> List[TableDef]:
        return self._tables
    
    def get_queries(self) -> List[QueryPattern]:
        return self._queries


class AutoGeneratedWorkload(Workload):
    """
    Workload with auto-generated tables.
    
    Example: Benchmark with 30 tables, 5 features each, 100M rows per table
    
    Usage:
        workload = AutoGeneratedWorkload(
            name="Generic Benchmark",
            num_tables=30,
            features_per_table=5,
            rows_per_table=100_000_000,
            query_strategy=QueryStrategy.BINPACKED_SP  # or SINGLE_TABLE, etc.
        )
    """
    
    def __init__(
        self,
        name: str,
        num_tables: int,
        features_per_table: int,
        rows_per_table: int,
        query_strategy: QueryStrategy = QueryStrategy.SINGLE_TABLE,
        keys_per_table: int = 25,
        use_binpacking: bool = False,  # Whether to use stored procedure binpacking
        **kwargs
    ):
        super().__init__(name=name, **kwargs)
        self.num_tables = num_tables
        self.features_per_table = features_per_table
        self.rows_per_table = rows_per_table
        self.query_strategy = query_strategy
        self.keys_per_table = keys_per_table
        self.use_binpacking = use_binpacking
    
    def get_tables(self) -> List[TableDef]:
        """Generate table definitions"""
        tables = []
        
        for i in range(self.num_tables):
            # Generate column definitions
            columns = {
                "primary_key": "CHAR(64) PRIMARY KEY",
                "raw_fingerprint": "TEXT",
            }
            
            # Add feature columns
            for j in range(self.features_per_table):
                columns[f"feature_{j+1}_t{i:02d}"] = "NUMERIC"
            
            columns["updated_at"] = "BIGINT"
            
            tables.append(TableDef(
                name=f"feature_table_{i:02d}",
                columns=columns,
                rows=self.rows_per_table,
                primary_key="primary_key"
            ))
        
        return tables
    
    def get_queries(self) -> List[QueryPattern]:
        """Generate query patterns based on strategy"""
        
        if self.use_binpacking:
            # Single stored procedure that queries all tables
            return [
                QueryPattern(
                    name="binpacked_lookup",
                    strategy=QueryStrategy.BINPACKED_SP,
                    tables=[t.name for t in self.get_tables()],
                    keys_per_query=self.keys_per_table * self.num_tables,
                    stored_procedure=self._get_sp_name(),
                    description=f"Binpacked lookup across {self.num_tables} tables"
                )
            ]
        
        elif self.query_strategy == QueryStrategy.SINGLE_TABLE:
            # Separate query per table
            queries = []
            for i in range(self.num_tables):
                queries.append(QueryPattern(
                    name=f"lookup_table_{i:02d}",
                    strategy=QueryStrategy.SINGLE_TABLE,
                    query=f"SELECT * FROM feature_table_{i:02d} WHERE primary_key = ANY(%s::CHAR(64)[])",
                    tables=[f"feature_table_{i:02d}"],
                    keys_per_query=self.keys_per_table,
                    description=f"Lookup from table {i}"
                ))
            return queries
        
        elif self.query_strategy == QueryStrategy.MULTI_TABLE_JOIN:
            # Join queries (if tables have relationships)
            return [
                QueryPattern(
                    name="join_all_tables",
                    strategy=QueryStrategy.MULTI_TABLE_JOIN,
                    query=self._generate_join_query(),
                    tables=[t.name for t in self.get_tables()],
                    keys_per_query=1,
                    description="Join across all tables"
                )
            ]
        
        else:
            raise ValueError(f"Unsupported query strategy: {self.query_strategy}")
    
    def _get_sp_name(self) -> str:
        """Get stored procedure name for binpacking"""
        return f"{self.name.lower().replace(' ', '_')}_batch_lookup"
    
    def _generate_join_query(self) -> str:
        """Generate JOIN query (placeholder - needs table relationships)"""
        # This would need foreign key relationships defined
        return "-- JOIN query needs foreign key relationships"
    
    def generate_stored_procedure(self) -> Optional[str]:
        """Generate stored procedure SQL for binpacking"""
        if not self.use_binpacking:
            return None
        
        tables = self.get_tables()
        sp_name = self._get_sp_name()
        
        # Build stored procedure SQL
        sql = f"CREATE OR REPLACE FUNCTION features.{sp_name}(\n"
        
        # Parameters (one TEXT[] per table)
        params = [f"    keys_{i:02d} TEXT[]" for i in range(len(tables))]
        sql += ",\n".join(params) + "\n"
        
        sql += """)\nRETURNS TABLE(
    table_name TEXT,
    data JSONB
)
LANGUAGE plpgsql
STABLE PARALLEL SAFE
AS $$
BEGIN
    -- CRITICAL: Cast TEXT[] to CHAR(64)[] to enable index usage
    
"""
        
        # Add RETURN QUERY for each table
        for i, table in enumerate(tables):
            sql += f"""    RETURN QUERY
    SELECT 
        '{table.name}'::TEXT,
        to_jsonb(t.*) AS data
    FROM features.{table.name} t
    WHERE primary_key = ANY(keys_{i:02d}::CHAR(64)[]);
    
"""
        
        sql += """    RETURN;
END;
$$;
"""
        
        return sql


# Convenience function for quick workload creation
def create_workload(
    mode: str,
    name: str = "Custom Workload",
    **kwargs
) -> Workload:
    """
    Factory function to create a workload.
    
    Args:
        mode: Either "schema" (user-defined) or "auto" (auto-generated)
        name: Workload name
        **kwargs: Additional arguments for the workload type
    
    Returns:
        Workload instance
    
    Examples:
        # Auto-generated (flexible benchmark)
        workload = create_workload(
            mode="auto",
            num_tables=30,
            features_per_table=5,
            rows_per_table=100_000_000,
            use_binpacking=True
        )
        
        # Schema-defined (specific use case)
        workload = create_workload(
            mode="schema",
            tables=[...],
            queries=[...]
        )
    """
    if mode == "auto":
        return AutoGeneratedWorkload(name=name, **kwargs)
    elif mode == "schema":
        return SchemaDefinedWorkload(name=name, **kwargs)
    else:
        raise ValueError(f"Unknown mode: {mode}. Use 'auto' or 'schema'")


if __name__ == "__main__":
    # Example 1: Auto-generated workload (like flexible benchmark)
    print("Example 1: Auto-generated workload with binpacking")
    workload1 = create_workload(
        mode="auto",
        name="30 Tables Benchmark",
        num_tables=30,
        features_per_table=5,
        rows_per_table=100_000_000,
        use_binpacking=True,  # Use stored procedure binpacking
        keys_per_table=25
    )
    print(f"  Tables: {len(workload1.get_tables())}")
    print(f"  Queries: {len(workload1.get_queries())}")
    print(f"  Query strategy: {workload1.get_queries()[0].strategy}")
    
    # Example 2: Auto-generated without binpacking (individual table reads)
    print("\nExample 2: Auto-generated workload with individual table reads")
    workload2 = create_workload(
        mode="auto",
        name="Individual Reads",
        num_tables=10,
        features_per_table=3,
        rows_per_table=10_000_000,
        use_binpacking=False,  # No binpacking - test individual reads
        query_strategy=QueryStrategy.SINGLE_TABLE
    )
    print(f"  Tables: {len(workload2.get_tables())}")
    print(f"  Queries: {len(workload2.get_queries())}")
    print(f"  Query strategy: {workload2.get_queries()[0].strategy}")
    
    # Example 3: Schema-defined (like fraud detection)
    print("\nExample 3: Schema-defined workload (fraud detection style)")
    fraud_tables = [
        TableDef(
            name="fraud_reports_365d",
            columns={
                "primary_key": "CHAR(64) PRIMARY KEY",
                "fraud_reports_365d": "NUMERIC",
                "fraud_rate_365d": "NUMERIC",
            },
            rows=1_000_000
        )
    ]
    fraud_queries = [
        QueryPattern(
            name="fraud_lookup",
            strategy=QueryStrategy.SINGLE_TABLE,
            query="SELECT * FROM fraud_reports_365d WHERE primary_key = ANY(%s::CHAR(64)[])",
            tables=["fraud_reports_365d"],
            keys_per_query=25
        )
    ]
    workload3 = create_workload(
        mode="schema",
        name="Fraud Detection",
        tables=fraud_tables,
        queries=fraud_queries
    )
    print(f"  Tables: {len(workload3.get_tables())}")
    print(f"  Queries: {len(workload3.get_queries())}")

